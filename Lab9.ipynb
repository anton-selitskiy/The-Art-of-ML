{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3b7edccd",
      "metadata": {
        "id": "3b7edccd"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib import cm\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#import numpy as np\n",
        "#from matplotlib import pyplot as plt\n",
        "#import seaborn as sns\n",
        "#%pylab inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 10"
      ],
      "metadata": {
        "id": "3hK7LxVXUCG4"
      },
      "id": "3hK7LxVXUCG4"
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "_bqTFWiCUA5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb026039-066e-44ea-f40c-59c5e7f75f48"
      },
      "id": "_bqTFWiCUA5p",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP_5mS7QUH_U",
        "outputId": "1c3857a8-398b-47ae-91a7-68b6801ccd6a"
      },
      "id": "BP_5mS7QUH_U",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255."
      ],
      "metadata": {
        "id": "m6C5U-1MUJlx"
      },
      "id": "m6C5U-1MUJlx",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[0], cmap=\"binary\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "wUcw0VpeULwj",
        "outputId": "f44435a6-43bb-4ddb-8b3a-93b9a47e22ad"
      },
      "id": "wUcw0VpeULwj",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwYsCGePUNME",
        "outputId": "40007ea2-0ef3-4d29-fc03-f17a7aed2f85"
      },
      "id": "CwYsCGePUNME",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gskkILTnUPcx",
        "outputId": "715c476c-788d-4f1a-fd61-b50c7f52a33a"
      },
      "id": "gskkILTnUPcx",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_rows = 4\n",
        "n_cols = 10\n",
        "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
        "        plt.axis('off')\n",
        "        plt.title(y_train[index], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "ZB4vg3CLUQuo",
        "outputId": "6583fb3e-3a3a-4ffd-e34d-56ce99b34443"
      },
      "id": "ZB4vg3CLUQuo",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x345.6 with 40 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = keras.backend\n",
        "\n",
        "class ExponentialLearningRate(keras.callbacks.Callback):\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "        self.rates = []\n",
        "        self.losses = []\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
        "        self.losses.append(logs[\"loss\"])\n",
        "        K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)"
      ],
      "metadata": {
        "id": "AHlbGMODUV2H"
      },
      "id": "AHlbGMODUV2H",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "KeqGo_-NUWVj"
      },
      "id": "KeqGo_-NUWVj",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])\n",
        "expon_lr = ExponentialLearningRate(factor=1.005)"
      ],
      "metadata": {
        "id": "o2GGP4zPUakj"
      },
      "id": "o2GGP4zPUakj",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=1,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[expon_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2QkD8M9UrJ8",
        "outputId": "2410cfe7-b84b-4262-ff40-6e40c756ae05"
      },
      "id": "a2QkD8M9UrJ8",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1719/1719 [==============================] - 11s 6ms/step - loss: nan - accuracy: 0.5658 - val_loss: nan - val_accuracy: 0.0958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(expon_lr.rates, expon_lr.losses)\n",
        "plt.gca().set_xscale('log')\n",
        "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
        "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
        "plt.grid()\n",
        "plt.xlabel(\"Learning rate\")\n",
        "plt.ylabel(\"Loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "QEpf9K7CUro-",
        "outputId": "172457d5-f3eb-4ff0-b7c7-09b86d1b76d6"
      },
      "id": "QEpf9K7CUro-",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUZb7H8c9vUkghBQiEEHqvAhI6YqyLWBAVy9pXZV37eldd7+69u3rX7eraFbuugg0VG7iWUAVpAQREg7QEEOmEHnjuHxk0YoiZMWcmmfN9v17zYuacMzO/PCTznec85zzHnHOIiIh/BaJdgIiIRJeCQETE5xQEIiI+pyAQEfE5BYGIiM8pCEREfC4+2gWEKi4lw3Xv1I6EOGWYl3bu3Elqamq0y4h5aueatWTddjKTE2iWmfy95WpnmDt37kbnXOPK1tW5IIjPaMJL7xXQuWl6tEuJaQUFBeTn50e7jJindq5Zve58nxE9m3HHiO7fW652BjNbdaR1nn2tNrMWZvaxmS0xs8VmdmMl2+Sb2TYzKwze/rc6r71734GaL1hE6jydHxseL3sEZcB/OefmmVkaMNfM/uOcW3LYdlOdc6eF8sK79ysIRKRyZhbtEuocz3oEzrl1zrl5wfs7gKVAbk289h4FgYhUQlPmhCciYwRm1hroDcyqZPVAM1sArAV+45xbXMnzRwOjARKbtuc34+ZyT36KdwULpaWlFBQURLuMmKd2rlllZWWUlBRTUPDN95arnavmeRCYWX3gNeAm59z2w1bPA1o550rNbDjwBtDh8Ndwzo0BxgDUy+ngNu9xXDZxJ/P+5yQapiZ6/BP4kwbXIkPtXLPiCiaRm9uc/Pxu31uudq6ap8dgmlkC5SHwgnNu/OHrnXPbnXOlwfvvAglmllXVa2anJ317/+j/+0/NFiwidZ6GCELn5VFDBjwJLHXO3XOEbZoGt8PM+gXr2VTV6zauX4/+bRp++3h60Ua27NzHlC++4eBB7R8U8TV9BITFy11Dg4GLgUVmVhhc9t9ASwDn3KPAOcCvzKwM2A2c735ktMcMXvrlQEq27ub4fxZw4RPfDTsc0yGLBy84moyUBA9+HBGpCwx1CULlWRA456ZB1f8jzrkHgQfDef3czGQ+uPlY8v9ZwIGDjqOaZzD1y430vPN9/nZ2D07pkUNavXgdSibiI+oQhKfOnVlcUYuGKRTddQoHHcQFjBnLN3LtC/O47bVF3PbaIto1TuXGEztyWo8cAgEFgogf6Ltf6Op0EED5ySNxwf/4Qe2ymP27E/l05WY+WLKBCQtKuGHsfJ6ctoJLBrSiX5uGtGiow05FYpXOIwhPnQ+Cw8XHBRjULotB7bL43aldeLOwhLvf/4L/emUBAAPbNuK649szqF0j7TYSiUH6qw5dzAVBRXEB46yjm3Nmr1w+X7+Dj5dt4PlPVnHhE7No36Q+Q9pn8YvBbWjZSL0EkVig/kB4YjoIDgkEjK7N0unaLJ0rhrTh5TlreHfROl6ctZp/z1zF0I6NOfvo5pzYtQn14uOiXa6I/ATq6IfOF0FQUVJCHJcMbM0lA1vz9fY9PDVtBRMWrOXaF+eRmZLAiJ7NGJXXgu65GdEuVURCpCGC8PguCCrKTk/i9uFduHVYZ6YXbeTlOWsYO3sNz36yii456ZzeM4dj2jema7N04nTUkUidoLG/0Pk6CA6JCxhDOzZmaMfGbNu1nzcXlPDa3GL+PnEZf2cZDVISOPWoHEb2zuXolg30iyZSSzmNEoRFQXCYjJSEb3cdbdixh0+Wb+KDpRt4dW4x/565muz0epx9dHOGdW9K92YZOj9BpJbRX2ToFARVaJKWxIheuYzolcuOPfuZ+Nl63l20jsemfMXDBcvJTElgcPssTunelGM7NiYtSVNbiESTxgjCoyCoprSkBEbltWBUXgs2Bye5m1a0kYJlG3hn4ToS4wLkd2rMqLwW5HdqTEKcpxO7isiRqEsQMgVBGBqmJnJm71zO7J3LgYOOuau2MPGz9UxYUML7S74mq349RvZuxpm9c+mak64xBZEIUYcgPAqCnyguYPRr05B+bRpy+/DOFCz7hlfmrOHp6St5fOoKOjSpz6i85pzZO5cmaUk//oIi8pNo9tHQKQhqUEJcgJO6ZnNS12w2le5l4uL1vDq3mD+/+zl/m7iMwe2zOPvoXE7u2pTkRJ24JlLj1CUIi4LAI43q1+PC/q24sH8rijbsYPy8Et4sXMuN4wqpXy+eU7o35ayjm9O/TUMdeSRSg7QnNnQKggho3ySNW4d15jcnd+LTlZsZP6+Ydxet55W5xeRmJnNm72acfXRz2jauH+1SReo0nUcQHgVBBAUCxoC2jRjQthF3nNGd95esZ/y8Eh4pWM5DHy9naMfGXD64Ncd2aKxegkiY9JcTOgVBlCQnxn17jsKG7XsYN3sNz89cxeVPz6ZtViqXDmrN2X2aU7+e/otEqkvnEYRHB7vXAk3Sk7jhhA5Mv+147ju/F2nJCfxhwmIG/vlD7nxrCas27Yx2iSJ1hsYIQqevm7VIYnzg217C/NVbeHr6Sp77ZCVPz1jBCZ2b8Mtj29G3dcNolylSa6lDEB4FQS3Vu2UDerdswO9O7cILM1fxwqzVjHr0Ewa3b8RNJ3ZUIIgcgc4jCJ12DdVy2elJ3HxyJ6bddjy/P7ULy9bvYNSjn3DhEzOZvXJztMsTqVV0zeLwKAjqiOTEOK48pi1Tb/1+IFz0xCwK12yNdnkitYbGCEKnIKhjDg+EJeu2c+ZD0/nl83P44usd0S5PJKrUHwiPgqCOOhQIU249jl+f2JHpRZsY9q8p3D5+Id/s2Bvt8kSiRh2C0CkI6rj69eK58cQOTL31OC4d1JpX5hRz3D8LeKRgOXv2H4h2eSIRpSGC8CgIYkSD1ET+cHo3Jv16KAPaNuRvEz/npHsn8+6idRpAE3/RIEHIFAQxpl3j+jxxaV/+fUV/UhLiueaFeZz32EwWFW+LdmkiUkspCGLUkA5ZvHPDEO4a2Z3l35RyxkPT+M0rC9i8c1+0SxPxlPoDoVMQxLD4uAAX9m/Fx7fkM/qYtrxZWMLJ907hw6VfR7s0kRqnXaDhUxD4QHpSArcP78Kb1w4hq34iVzw7h1teWcDWXeodSOzREEHoFAQ+0rVZOm9eN5hr8tsxfn4JJ94zmQkL1uqblMQE/RqHT0HgM/Xi47h1WGfeum4IuZnJ3DB2Plc9N5d123ZHuzSRGqG5hkLnWRCYWQsz+9jMlpjZYjO7sZJtzMzuN7MiM1toZkd7VY98X9dm6Yy/ZjC/G96FaUXfcPI9U3izsCTaZYmETR2C8HnZIygD/ss51xUYAFxrZl0P2+YUoEPwNhp4xMN65DBxAeOqoW2ZdNNQOjVN48Zxhfz6pUJ27Nkf7dJEwqYxgtB5FgTOuXXOuXnB+zuApUDuYZuNAJ5z5WYCmWaW41VNUrlWjVIZN3oAN53YgTcLSxh+/1SKtuisZBG/iMj1CMysNdAbmHXYqlxgTYXHxcFl6w57/mjKewxkZ2dTUFDgUaX+1isebu+XxGML9/DnWQf5Ysv7DGuTQEBfsTxTWlqq3+cacuBg+c6hFStWUFDw/d2caueqeR4EZlYfeA24yTm3PZzXcM6NAcYA5OXlufz8/JorUL4nHzjvlP384pEPefmL/WwKNOCec3uRkZIQ7dJiUkFBAfp9rhllBw7C++/Rtk0b8vM7fG+d2rlqnh41ZGYJlIfAC8658ZVsUgK0qPC4eXCZRFF6UgLX9qrHH0/vypQvv+H0B6exZG1YGS4SMRosDp+XRw0Z8CSw1Dl3zxE2mwBcEjx6aACwzTm37gjbSgSZGZcNbsO40QPZW3aAsx6ZzlsL1ka7LJEfpT2ZofOyRzAYuBg43swKg7fhZna1mV0d3OZd4CugCHgcuMbDeiQMfVo14O3rj6FHbgbXj53PX9/7/Nt9sSK1iU4oC59nYwTOuWn8yPxPrvyU1mu9qkFqRuO0erxw5QDueGsxj05ezufrt3Pf+b3JSNa4gdQ+pi5ByHRmsVRLYnyAu0b24K6R3ZletJEzH5pO0QZdGlNqD6dRgrApCCQkF/ZvxYtXDWDHnv2c+dAMPliimUxF6joFgYSsb+uGTLhuCK2zUrjyuTn8ccJidu/TCWgSXRojCJ+CQMLSLDOZV68exGWDWvPMjJWMfHg6azbvinZZIjpqKAwKAglbUkIcfzyjG09f3peSrbsZ8dB0Pl2xOdpliUiIFATykx3XqQlvXDuYzOQEfv74TJ6evkLXOJCo0TTUoVMQSI1o17g+r187mPxOTbjjrSXcOK5Q4wYSUfruET4FgdSYjOQExlzch1t+1om3Fq7l7EdmaNxAIk5jBKFTEEiNCgSMa49rz1OX9mXNll2cev9UJn62PtpliQ/oPILwKQjEE8d1bsI71x9D66xUrv73XP709pLy2SFFPKYOQegUBOKZlo1SePXqQVw6sBVPTFvBRU/OYmPp3miXJTFKYwThUxCIpxLjA9wxojv3nNuT+au3ctr905i/eku0y5IYpjGC0CkIJCLOOro5468ZREK8cd5jM3lx1modYio1Sr9N4VMQSMR0a5bBW9cNYWC7Rvz364u47bWF7NmvQ0ylZuk8gtApCCSiMlMSeeqyvtxwfHtenlPMqEc/oXiLDjGVn049zPApCCTi4gLGzSd34vFL8li5cSenPzCNyV98E+2yJEZojCB0CgKJmpO6ZvPmdYPJTk/isqc/5d7/fKGrn0nY9JsTPgWBRFXbxvV5/ZrBjOydy30ffsllT3/KJh1iKhJRCgKJuuTEOO4e1ZO/ntWDWSs2c9oD05i7SoeYSmg0RBA+BYHUCmbG+f1aMv5Xg0iIC3DeY58wZspyDmpXkYRI1ywOnYJAapXuuRm8df0QTujShD+/+zmXPzNbZyNL9eg7Q9gUBFLrZCQn8OhFffi/M7vzyVebOOW+qUwv2hjtsqSOUH8gdAoCqZXMjIsHtOLNaweTkZzARU/O4h+TPtfEdXJEmn00fAoCqdW65KQz4brBnNunBQ99vJzzxszUCWhSJQ0RhE5BILVeSmI8fzvnKO6/oDfL1u9g+H1TmfjZumiXJbWMjhoKn4JA6owzejbjnRuG0CYrlav/PY/fv7FIcxXJD6hDEDoFgdQprRql8srVgxg9tC3/nrma4fdNZZ6mtRZ00NBPoSCQOicxPsB/D+/CC1f2Z2/ZQc55ZAZ/eW+pegcC6DyCcCgIpM4a3D6LiTcdw3l9W/DY5K84/YFpLCzeGu2yJEo0+2j4FARSp6UlJfCXs47i2V/0Y8eeMkY+PIO731/GvjIdZupX6hCETkEgMeHYjo2Z9OuhjOydywMfFXHGg9P4rGRbtMuSCFJ/IHwKAokZGckJ/HNUT568NI9NO/cx4qHp/H3i5xo78Bl1CEKnIJCYc0KXbD749bGM7J3LwwXLOeneybrwjQ9oiCB8ngWBmT1lZhvM7LMjrM83s21mVhi8/a9XtYj/ZKSU9w5evKo/9eLjuPSpT7nllQVs3rkv2qWJ1zRIEDIvewTPAMN+ZJupzrlewdudHtYiPjWoXRZvXz+EX+W34/X5JRx/dwFjP12t6a1jkOYaCp9nQeCcmwJs9ur1RaorKSGO24Z15r0bj6FTdhq3j1/EWY/M0GByjFJ/IHTRHiMYaGYLzOw9M+sW5VokxnXITmPc6AHce15Pirfs4owHp/HHCYvZvmd/tEuTmqAOQdjMy5MwzKw18LZzrnsl69KBg865UjMbDtznnOtwhNcZDYwGyM7O7jNu3DjPapZypaWl1K9fP9pleGbnfsf4L/fx0eoy0usZF3RKpH9OXMTPSo31do6krXsOclPBbi7tmshxLRO+t07tDMcdd9xc51xeZeuiFgSVbLsSyHPOVXkFkry8PDdnzpwaqU+OrKCggPz8/GiX4bmFxVv5nzc+Y0HxNga1a8TvT+1K12bpEXt/v7RzJGzYvod+f/6Qu0Z258L+rb63Tu0MZnbEIIjariEza2rBr19m1i9Yy6Zo1SP+dFTzTMZfM5g/ndmdJeu2c+oDU7n55UJKtu6OdmkSIu0ZCl+8Vy9sZmOBfCDLzIqBPwAJAM65R4FzgF+ZWRmwGzjfabIQiYK4gHHRgFacflQzHp5cxNPTV/L2wnVcMaQNv8pvR3pSwo+/iNQapuHikHkWBM65C35k/YPAg169v0ioMlISuP2ULlwysDV3T1rGIwXLeWn2Gq7Jb8dFA1qRlBAX7RKlCofml4qPUxCEKtpHDYnUOrmZydxzXi/eum4I3Zql86d3lnL8Pwt4efYaXTO5Ftu1r3wqkdREz77fxiwFgcgR9GiewfNX9OeFK/uTlVaPW19byAn3TObVucUKhFpo574yAFLqqecWKgWByI8Y3D6LN68dzOOX5FG/Xjy/eWUBJ907hfHzijmgM5RrjV171SMIl4JApBrMjJO6ZvP29UN47OI+JCXEcfPLCzjpnsm8WViiQKgFDs0ym5Sgj7VQqcVEQmBm/KxbU965fgiPXHg0CXEBbhxXyM/+NYUJC9YqEKLoQPCgw4AmnQtZtYLAzFLNLBC839HMzjAzHVMnvhUIGKf0yOG9G4/hoZ8fTcDghrHzGfavKby9cK0mtYuCQ0efxwUUBKGqbo9gCpBkZrnA+8DFlM8uKuJrgYBx6lE5TLxxKA9c0BsHXPfifE65bypvzC9hvwaVI+ZQ9qpHELrqBoE553YBZwEPO+dGAZokTiQoEDBO79mMSTcN5b7ze3HQOW56qZD8fxTw+JSv2LZLE9t57dBuOXUIQlftIDCzgcCFwDvBZTpGS+QwcQFjRK9cJt00lCcvzSM3M5m73l3KgL98yG9fW6iprz10MLhrKNITB8aC6h5ndRNwO/C6c26xmbUFPvauLJG6LRAwTuiSzQldslm8dhvPf7KKNwpLGDd7DT1bZHLxgFacdlROtMuMKYcmqNEYQeiqFQTOucnAZIDgoPFG59wNXhYmEiu6Ncvgr2cfxe3Du/D6vGKen7mK37yygD+9s4SB2dC2xy5aNkqJdpl1nnYNha+6Rw29aGbpZpYKfAYsMbNbvC1NJLZkJCdw2eA2fHDzsbx4VX8GtWvEpJX7OfafH3P505/y4dKvdfjpT3BQh4+Grbq7hro657ab2YXAe8BvgbnAPzyrTCRGmRmD2mUxqF0Wr0/8iBWBXMbOXsMVz84hNzOZ8/u24Ly+LWiSnhTtUuuUQ7uGAuoShKy6QZAQPG/gTOBB59x+M9NXF5GfqEFSgJH5nbj+hA58sORrXpi1mrv/8wX3ffglJ3fL5sL+rRjYtpE+3KrhuxPKolxIHVTdIHgMWAksAKaYWStgu1dFifhNQlyAU3rkcEqPHFZs3MmLs1bxytxi3l20njZZqfy8X0vO6dOcBqmJ0S611tKuofBVa4zAOXe/cy7XOTfclVsFHOdxbSK+1CYrld+d2pWZt5/Avef1pFFqIne9u5T+f/mQX79UyJyVm9E1nH5IJ5SFr1o9AjPLoPwKY0ODiyYDdwI6KFrEI0kJcYzs3ZyRvZvz+frtvDhrNePnlfD6/BI6ZaeR17oBx3TIIr9TE100h++mmNCuodBVd9fQU5QfLXRu8PHFwNOUn2ksIh7r3DSdO0d057ZhnXlrwVrGzV7DhAVreWHWatKS4jm9ZzNG9WlOrxaZvj2h6rvDR/358/8U1Q2Cds65sys8vsPMCr0oSESOLLVePOf3a8n5/VpSduAgM5Zv4vX5JYyfV8yLs1bTqlEKZ/RsxohezWjfJC3a5UbUQR01FLbqBsFuMxvinJsGYGaDKb/gvIhESXxcgKEdGzO0Y2PuGNGNiYvWM2HBWh76uIgHPiqiS046px2Vw7DuTWnXuH60y/Wcdg2Fr7pBcDXwXHCsAGALcKk3JYlIqNKTEji3bwvO7duCDTv28M7CdUxYsJZ/TFrGPyYto13jVH7WrSk/69aUo5pnxOTuI+0aCl91p5hYAPQ0s/Tg4+1mdhOw0MviRCR0TdKSuHxwGy4f3IZ123bz/uKvmbR4PY9N+YqHC5aTm5nMqUflcPpRzeiemx4zoXBQcw2FLaSLezrnKp47cDPwr5otR0RqUk5GMpcOas2lg1qzZec+Pvx8A+8sXMtT01YwZspXtGqUwvAeOQyLgZ7Cd7OPRrmQOuinXOVZzS1ShzRITeScPs05p09ztu7ax6TF63l74TrGTPmKRwqWk5ORxM+6NeXkbtnktWpIYnzdupLtQe0aCttPCQKd0SJSR2WmJHJe35ac17clW3ft44OlG5i0eD1jP13NMzNWkpIYR/82DRncPoshHbLolJ1W63sLumZx+KoMAjPbQeUf+AYke1KRiERUZsp3PYVd+8qY+uVGphdtZFrRRj5+ZykAWfXrMbh9Iwa3z2Jw+yxyM2vfn//ufQdIjA9ojCAMVQaBc85fByKL+FxKYvy3RxcBrN26m+lFG5mxfBPTijbyZuFaANpmpQZDoRED22aRkZIQzbIB2LG3jPSkn7KTw7/UaiJyRM0ykxmV14JReS1wzvHlhlKmBXsM44MX2QkY9MjNKN+N1D6L3i0bkJwY+SkvSveUUb+ePtLCoVYTkWoxMzpmp9ExO41fDGnD/gMHWbBmK9OKyoNhTPDw1ICVT4kxqF0jBrVvRN/WDUlL8r7H8M2OvZqdNUwKAhEJS0JcgLzWDclr3ZCbTuxI6d4yPl2xicI12/h0xSaem7mKJ6atIC5gdM1J56jmGfRu2YD+bRrSLDO5Rvfll+4tY/bKzZx9dPMae00/URCISI2oXy+e4ztnc3znbAD27D/AvFVbmLF8E3NXbWFCYfkkeQAJcUaP3AySE+Po0CSNPq0a0CUnnWaZSaQkhv6xtHTddsoOOoZ0yKrRn8kvFAQi4omkhDgGtc9iUPvyD+eDBx1fbNjB7BWbWb15F4VrtlK6p4yXZq/hmRkrv31em6xUerfMpHeLTHq1aEDnnDQS4qo+p+GDpV8D0Ld1Q89+nlimIBCRiAgEjM5N0+ncNP17y/cfOMiy9Tv44usdlGzZzYLibUz54hvGzysBID5gtGyYQrfcDNpmpdIxO41OTdNolJrIjj1l5GQmMe3LjfRr3ZCmGbrOczisrl3pKC0tzfXp0yfaZcS8rVu3kpmZGe0yYp7auXIOKKuXzr76OexLacz+5Cz2pjbhQGL6EeeQaLDyIzLWz610ndoZJk+ePNc5l1fZOs96BGb2FHAasME5172S9QbcBwwHdgGXOefmeVWPiNQdBiTs3U7C3u2kblr27fKDFsf+lCz2JzfiQHwygQP7KEvKxFkcaRs0B2a4vNw19AzwIPDcEdafAnQI3voDjwT/rVKnTp0oKCiomQrliAoKCsjPz492GTFP7RwZameqnCLEs1mlnHNTgM1VbDICeM6VmwlkmlmOV/WIiEjlojlYnAusqfC4OLhs3eEbmtloYDRAdna2egQRUFpaqnaOALVzZKidq1Ynjhpyzo0BxgDk5eU5v3fxIkFd6chQO0eG2rlq0ZxwvARoUeFx8+AyERGJoGgGwQTgEis3ANjmnPvBbiEREfGWl4ePjgXygSwzKwb+ACQAOOceBd6l/NDRIsoPH73cq1pEROTIPAsC59wFP7LeAdd69f4iIlI9deuipCIiUuMUBCIiPqcgEBHxOQWBiIjPKQhERHxOQSAi4nMKAhERn1MQiIj4nIJARMTnFAQiIj6nIBAR8TkFgYiIzykIRER8TkEgIuJzCgIREZ9TEIiI+JyCQETE5xQEIiI+pyAQEfE5BYGIiM8pCEREfE5BICLicwoCERGfUxCIiPicgkBExOcUBCIiPqcgEBHxOQWBiIjPKQhERHxOQSAi4nMKAhERn1MQiIj4nIJARMTnPA0CMxtmZsvMrMjMflvJ+svM7BszKwzervSyHhER+aF4r17YzOKAh4CTgGJgtplNcM4tOWzTl5xz13lVh4iIVM3LHkE/oMg595Vzbh8wDhjh4fuJiEgYvAyCXGBNhcfFwWWHO9vMFprZq2bWwsN6RESkEp7tGqqmt4Cxzrm9ZvZL4Fng+MM3MrPRwGiA7OxsCgoKIlqkH5WWlqqdI0DtHBlq56p5GQQlQMVv+M2Dy77lnNtU4eETwN8reyHn3BhgDEBeXp7Lz8+v0ULlhwoKClA7e0/tHBlq56p5uWtoNtDBzNqYWSJwPjCh4gZmllPh4RnAUg/rERGRSnjWI3DOlZnZdcAkIA54yjm32MzuBOY45yYAN5jZGUAZsBm4zKt6RESkcp6OETjn3gXePWzZ/1a4fztwu5c1iIhI1XRmsYiIzykIRER8TkEgIuJzCgIREZ9TEIiI+JyCQETE5xQEIiI+pyAQEfE5BYGIiM8pCEREfE5BICLicwoCERGfUxCIiPicgkBExOcUBCIiPqcgEBHxOQWBiIjPKQhERHxOQSAi4nMKAhERn1MQiIj4nIJARMTnFAQiIj6nIBAR8TkFgYiIzykIRER8TkEgIuJzCgIREZ9TEIiI+JyCQETE5xQEIiI+pyAQEfE5BYGIiM8pCEREfM7TIDCzYWa2zMyKzOy3layvZ2YvBdfPMrPWXtYjIiI/5FkQmFkc8BBwCtAVuMDMuh622RXAFudce+Be4G9e1SMiIpXzskfQDyhyzn3lnNsHjANGHLbNCODZ4P1XgRPMzDysSUREDhPv4WvnAmsqPC4G+h9pG+dcmZltAxoBGytuZGajgdHBh6VmtsyTin8oA9gWoedXZ9uqtjnSusqWV2dZFof9P3hI7RwZaufIqK3t3OqIWzjnPLkB5wBPVHh8MfDgYdt8BjSv8Hg5kOVVTWH8DGMi9fzqbFvVNkdaV9ny6iwD5qid1c5q59hu50M3L3cNlQAtKjxuHlxW6TZmFk95cm3ysKZQvRXB51dn26q2OdK6ypZXd1mkqJ0jQ+0cGXWpnQGwYGLUuOAH+xfACZR/4M8Gfu6cW1xhm2uBHs65q83sfOAs59y5nhQkITGzOc65vGjXEevUzpGhdq6aZ2MErnyf/3XAJCAOeMo5t9jM7qS8mzYBeBJ43syKgM3A+V7VIyEbE+0CfELtHBlq5yp41iMQEZG6QWcWiyAb2MMAAASISURBVIj4nIJARMTnFAQiIj6nIJCQmdmZZvZ4cJ6ok6NdT6wys7Zm9qSZvRrtWmKNmaWa2bPB3+MLo11PtCkIfMbMnjKzDWb22WHLq5wgsCLn3BvOuauAq4HzvKy3rqqhdv7KOXeFt5XGjhDb/Czg1eDv8RkRL7aWURD4zzPAsIoLjjRBoJn1MLO3D7s1qfDU3wefJz/0DDXXzlI9z1DNNqf8BNdDU+AciGCNtZKXcw1JLeScm1LJdN/fThAIYGbjgBHOub8Apx3+GsGJAf8KvOecm+dtxXVTTbSzhCaUNqd87rPmQCH6QqwGEKDyCQJzq9j+euBE4Bwzu9rLwmJMSO1sZo3M7FGgt5nd7nVxMepIbT4eONvMHiG601HUCuoRSMicc/cD90e7jljnnNtE+TiM1DDn3E7g8mjXUVuoRyBQvQkC5adTO0ee2rwaFAQC5RMCdjCzNmaWSPmcTxOiXFMsUjtHntq8GhQEPmNmY4FPgE5mVmxmVzjnyoBDEwQuBV6uOEushE7tHHlq8/Bp0jkREZ9Tj0BExOcUBCIiPqcgEBHxOQWBiIjPKQhERHxOQSAi4nMKAokZZlYa4febEeH3yzSzayL5nuIPCgKRIzCzKufics4NivB7ZgIKAqlxCgKJaWbWzswmmtlcM5tqZp2Dy083s1lmNt/MPjCz7ODyP5rZ82Y2HXg++PgpMysws6/M7IYKr10a/Dc/uP5VM/vczF4ITtWNmQ0PLptrZveb2duV1HiZmU0ws4+AD82svpl9aGbzzGyRmY0IbvpXoJ2ZFZrZP4LPvcXMZpvZQjO7w8u2lBjmnNNNt5i4AaWVLPsQ6BC83x/4KHi/Ad+dWX8lcHfw/h+BuUByhcczgHpAFrAJSKj4fkA+sI3yCc0ClE9zMARIonwK5DbB7cYCb1dS42WUT4/cMPg4HkgP3s8CigADWgOfVXjeycCY4LoA8DYwNNr/D7rVvZumoZaYZWb1gUHAK8Ev6FD+gQ7lH9ovmVkOkAisqPDUCc653RUev+Oc2wvsNbMNQDblH9wVfeqcKw6+byHlH9qlwFfOuUOvPRYYfYRy/+Oc23yodODPZjYUOEj5/PnZlTzn5OBtfvBxfaADMOUI7yFSKQWBxLIAsNU516uSdQ8A9zjnJphZPuXf/A/Zedi2eyvcP0DlfzfV2aYqFd/zQqAx0Mc5t9/MVlLeuzicAX9xzj0W4nuJfI/GCCRmOee2AyvMbBSUX2LTzHoGV2fw3bz0l3pUwjKgbYXLJ55XzedlABuCIXAc0Cq4fAeQVmG7ScAvgj0fzCxX1zqWcKhHILEkxcwq7rK5h/Jv14+Y2e+BBGAcsIDyHsArZrYF+AhoU9PFOOd2Bw/3nGhmOymfG786XgDeMrNFwBzg8+DrbTKz6Wb2GeXXi77FzLoAnwR3fZUCFwEbavpnkdimaahFPGRm9Z1zpcGjiB4CvnTO3RvtukQq0q4hEW9dFRw8Xkz5Lh/tz5daRz0CERGfU49ARMTnFAQiIj6nIBAR8TkFgYiIzykIRER8TkEgIuJz/w+hhGFcFJZ7JQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "5yrtcIUCUtZG"
      },
      "id": "5yrtcIUCUtZG",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=3e-1),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "-sokvAQVU1Hc"
      },
      "id": "-sokvAQVU1Hc",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "run_index = 1 # increment this at every run\n",
        "run_logdir = os.path.join(os.curdir, \"my_mnist_logs\", \"run_{:03d}\".format(run_index))\n",
        "run_logdir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oC2-hohaU1mW",
        "outputId": "6ea50ccf-2257-4225-beb7-fb09b4434345"
      },
      "id": "oC2-hohaU1mW",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./my_mnist_logs/run_001'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzkYZDt3U3PZ",
        "outputId": "126224aa-a9d8-4cc2-874a-e3f3f529f8c8"
      },
      "id": "OzkYZDt3U3PZ",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.2362 - accuracy: 0.9266 - val_loss: 0.0978 - val_accuracy: 0.9704\n",
            "Epoch 2/100\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0946 - accuracy: 0.9703 - val_loss: 0.0926 - val_accuracy: 0.9730\n",
            "Epoch 3/100\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0664 - accuracy: 0.9787 - val_loss: 0.0827 - val_accuracy: 0.9756\n",
            "Epoch 4/100\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0476 - accuracy: 0.9850 - val_loss: 0.0750 - val_accuracy: 0.9790\n",
            "Epoch 5/100\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.0354 - accuracy: 0.9880 - val_loss: 0.0788 - val_accuracy: 0.9784\n",
            "Epoch 6/100\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0300 - accuracy: 0.9904 - val_loss: 0.0768 - val_accuracy: 0.9794\n",
            "Epoch 7/100\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0807 - val_accuracy: 0.9796\n",
            "Epoch 8/100\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0716 - val_accuracy: 0.9818\n",
            "Epoch 9/100\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 0.0931 - val_accuracy: 0.9800\n",
            "Epoch 10/100\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.0783 - val_accuracy: 0.9844\n",
            "Epoch 11/100\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.0847 - val_accuracy: 0.9838\n",
            "Epoch 12/100\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0891 - val_accuracy: 0.9814\n",
            "Epoch 13/100\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.0878 - val_accuracy: 0.9824\n",
            "Epoch 14/100\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.1087 - val_accuracy: 0.9812\n",
            "Epoch 15/100\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1000 - val_accuracy: 0.9806\n",
            "Epoch 16/100\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0864 - val_accuracy: 0.9836\n",
            "Epoch 17/100\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0862 - val_accuracy: 0.9854\n",
            "Epoch 18/100\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 4.9891e-04 - accuracy: 0.9999 - val_loss: 0.0833 - val_accuracy: 0.9866\n",
            "Epoch 19/100\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.3572e-04 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9860\n",
            "Epoch 20/100\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 7.4768e-05 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9872\n",
            "Epoch 21/100\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 6.0104e-05 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9872\n",
            "Epoch 22/100\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 5.2219e-05 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9872\n",
            "Epoch 23/100\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 4.6609e-05 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9872\n",
            "Epoch 24/100\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 4.2480e-05 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9872\n",
            "Epoch 25/100\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 3.9197e-05 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9872\n",
            "Epoch 26/100\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 3.6543e-05 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9872\n",
            "Epoch 27/100\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 3.4127e-05 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9872\n",
            "Epoch 28/100\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 3.2038e-05 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_mnist_model.h5\") # rollback to best model\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMArfl96U5UL",
        "outputId": "7b57d2c3-7cce-4c23-cc7c-3f761803930b"
      },
      "id": "sMArfl96U5UL",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0830 - accuracy: 0.9809\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08301407098770142, 0.98089998960495]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a941fa14",
      "metadata": {
        "id": "a941fa14"
      },
      "source": [
        "## Hyperparameter Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "8aPNHxyv9lrP"
      },
      "id": "8aPNHxyv9lrP",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "96eb8439",
      "metadata": {
        "id": "96eb8439"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e03921ba",
      "metadata": {
        "id": "e03921ba"
      },
      "outputs": [],
      "source": [
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "27116836",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27116836",
        "outputId": "38a3ed06-1408-4b25-ddb9-6269fbab60b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9e76d264",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e76d264",
        "outputId": "291a6753-5c91-4863-dadb-1ac5a3a9c0bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 6s 11ms/step - loss: 1.0896 - val_loss: 20.7721\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 3s 9ms/step - loss: 0.7606 - val_loss: 5.0266\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 3s 9ms/step - loss: 0.5456 - val_loss: 0.5490\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.4732 - val_loss: 0.4529\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 3s 9ms/step - loss: 0.4503 - val_loss: 0.4188\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.4338 - val_loss: 0.4129\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4241 - val_loss: 0.4004\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4168 - val_loss: 0.3944\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4108 - val_loss: 0.3961\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4071\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4021 - val_loss: 0.3855\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4136\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.3997\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3921 - val_loss: 0.3818\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3894 - val_loss: 0.3829\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.3739\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3848 - val_loss: 0.4022\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.3873\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3807 - val_loss: 0.3768\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3791 - val_loss: 0.4191\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3774 - val_loss: 0.3927\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.4237\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3523\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3725 - val_loss: 0.3842\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.4162\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.3980\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.3474\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.3920\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3670 - val_loss: 0.3566\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3653 - val_loss: 0.4191\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.3721\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3633 - val_loss: 0.3948\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3632 - val_loss: 0.3423\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.3453\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.4068\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.3417\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3596 - val_loss: 0.3787\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3379\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3419\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3705\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.3659\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3563 - val_loss: 0.3803\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3552 - val_loss: 0.3765\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.3813\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3543 - val_loss: 0.3326\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3532 - val_loss: 0.3385\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3527 - val_loss: 0.3655\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3521 - val_loss: 0.3579\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.3360\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3510 - val_loss: 0.3317\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3504 - val_loss: 0.3562\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3502 - val_loss: 0.3521\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.4579\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3809\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3540\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.3725\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3478 - val_loss: 0.3337\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3469 - val_loss: 0.4011\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3476 - val_loss: 0.3263\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.3271\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3453 - val_loss: 0.3349\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3454 - val_loss: 0.3541\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.3428\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3451 - val_loss: 0.3280\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3437 - val_loss: 0.3292\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3301\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3428 - val_loss: 0.3254\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3423 - val_loss: 0.3245\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3419 - val_loss: 0.3255\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3413 - val_loss: 0.3666\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3414 - val_loss: 0.3370\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3405 - val_loss: 0.3267\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3400 - val_loss: 0.3245\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3402 - val_loss: 0.3663\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3397 - val_loss: 0.3290\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3395 - val_loss: 0.3235\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3386\n",
            "Epoch 78/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3384 - val_loss: 0.3362\n",
            "Epoch 79/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3384 - val_loss: 0.3222\n",
            "Epoch 80/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3376 - val_loss: 0.3644\n",
            "Epoch 81/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3384 - val_loss: 0.3420\n",
            "Epoch 82/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3371 - val_loss: 0.3253\n",
            "Epoch 83/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3368 - val_loss: 0.3246\n",
            "Epoch 84/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3362 - val_loss: 0.3953\n",
            "Epoch 85/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3372 - val_loss: 0.3415\n",
            "Epoch 86/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3359 - val_loss: 0.3190\n",
            "Epoch 87/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3356 - val_loss: 0.3277\n",
            "Epoch 88/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3351 - val_loss: 0.3295\n",
            "Epoch 89/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3348 - val_loss: 0.3247\n",
            "Epoch 90/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3344 - val_loss: 0.3281\n",
            "Epoch 91/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3341 - val_loss: 0.3201\n",
            "Epoch 92/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.3393\n",
            "Epoch 93/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3336 - val_loss: 0.3170\n",
            "Epoch 94/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3334 - val_loss: 0.3526\n",
            "Epoch 95/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3329 - val_loss: 0.4813\n",
            "Epoch 96/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3339 - val_loss: 0.3465\n",
            "Epoch 97/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3324 - val_loss: 0.4632\n",
            "Epoch 98/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3333 - val_loss: 0.6725\n",
            "Epoch 99/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3330 - val_loss: 0.5924\n",
            "Epoch 100/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3343 - val_loss: 0.5272\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fab1832af90>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "keras_reg.fit(X_train, y_train, epochs=100,\n",
        "              validation_data=(X_valid, y_valid),\n",
        "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "50733161",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50733161",
        "outputId": "f570ae4f-9313-420e-b668-684b71fbd249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 0.3346\n"
          ]
        }
      ],
      "source": [
        "mse_test = keras_reg.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d40289cb",
      "metadata": {
        "id": "d40289cb"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "5ac8fd18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5ac8fd18",
        "outputId": "e431b722-5dcb-46fe-f258-a877a8652ff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8420 - val_loss: 0.4703\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4815 - val_loss: 0.4247\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4519 - val_loss: 0.4052\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4429 - val_loss: 0.3975\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4368 - val_loss: 0.3991\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4340 - val_loss: 0.4031\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4351 - val_loss: 0.4043\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4267 - val_loss: 0.3929\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4258 - val_loss: 0.4040\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4237 - val_loss: 0.3886\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4209 - val_loss: 0.3999\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.4085\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4139 - val_loss: 0.3922\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.3918\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4106 - val_loss: 0.3886\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4092 - val_loss: 0.3933\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4092 - val_loss: 0.3907\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4087 - val_loss: 0.3955\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4058 - val_loss: 0.3935\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4053 - val_loss: 0.3891\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4251\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  13.0s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7452 - val_loss: 0.4860\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4649 - val_loss: 0.4280\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4495 - val_loss: 0.5791\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4438 - val_loss: 0.4549\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4414 - val_loss: 0.5250\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4409 - val_loss: 0.5486\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4388 - val_loss: 0.5871\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4381 - val_loss: 0.4759\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4371 - val_loss: 0.7523\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4369 - val_loss: 0.7478\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4344 - val_loss: 0.8981\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4347 - val_loss: 0.8543\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4537\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  10.9s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 10.8725 - val_loss: 4.2468\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0257 - val_loss: 0.5794\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5263 - val_loss: 0.4357\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4640 - val_loss: 0.4169\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4515 - val_loss: 0.4135\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4486 - val_loss: 0.4206\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4567 - val_loss: 0.4100\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4495 - val_loss: 0.4155\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4111\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4620 - val_loss: 0.4076\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4470 - val_loss: 0.4062\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4460 - val_loss: 0.4078\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4462 - val_loss: 0.4160\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4445 - val_loss: 0.4158\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4430 - val_loss: 0.4137\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4515 - val_loss: 0.4069\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4422 - val_loss: 0.4119\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4408 - val_loss: 0.4149\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4429 - val_loss: 0.4081\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4595 - val_loss: 0.4141\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4431 - val_loss: 0.4100\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4473\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  13.6s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.1684 - val_loss: 6.2480\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6285 - val_loss: 5.2166\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5212 - val_loss: 0.4474\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4280 - val_loss: 0.3901\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4008 - val_loss: 0.3736\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3840 - val_loss: 0.3803\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3730 - val_loss: 0.3813\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3648 - val_loss: 0.3961\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3591 - val_loss: 0.3988\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3542 - val_loss: 0.3891\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3510 - val_loss: 0.3870\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3465 - val_loss: 0.3769\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3424 - val_loss: 0.3770\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3407 - val_loss: 0.3848\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3371 - val_loss: 0.3769\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3561\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  21.2s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8828 - val_loss: 3.5738\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4887 - val_loss: 0.7767\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4267 - val_loss: 0.5515\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4011 - val_loss: 0.5335\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3852 - val_loss: 0.5336\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3746 - val_loss: 0.6750\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3678 - val_loss: 0.8462\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.8724\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3554 - val_loss: 0.9645\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.7225\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3475 - val_loss: 0.7257\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3442 - val_loss: 0.7217\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3422 - val_loss: 0.8443\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3407 - val_loss: 0.7065\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3650\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  11.0s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0015 - val_loss: 2.9433\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5546 - val_loss: 4.2557\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4854 - val_loss: 2.8526\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4594 - val_loss: 1.6798\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4136 - val_loss: 0.4322\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3937 - val_loss: 0.4172\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3829 - val_loss: 0.3769\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3753 - val_loss: 0.3688\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3692 - val_loss: 0.4032\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3655 - val_loss: 0.3418\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3610 - val_loss: 0.4452\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.3454\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3526 - val_loss: 0.3395\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3503 - val_loss: 0.4354\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3489 - val_loss: 0.3386\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3455 - val_loss: 0.4038\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3434 - val_loss: 0.3302\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3406 - val_loss: 0.3580\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3386 - val_loss: 0.3546\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3360 - val_loss: 0.3460\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3355 - val_loss: 0.3244\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.3257\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3315 - val_loss: 0.3441\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3301 - val_loss: 0.3377\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3289 - val_loss: 0.3651\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3271 - val_loss: 0.3924\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3256 - val_loss: 0.3141\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3237 - val_loss: 0.3201\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3250 - val_loss: 0.4308\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3232 - val_loss: 0.3204\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3196 - val_loss: 0.3129\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3177 - val_loss: 0.4282\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3187 - val_loss: 0.3116\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3152 - val_loss: 0.3920\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3173 - val_loss: 0.4133\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3138 - val_loss: 0.6989\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3161 - val_loss: 0.7475\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3227 - val_loss: 1.0271\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3186 - val_loss: 0.4150\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3119 - val_loss: 0.6728\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3126 - val_loss: 0.3501\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3079 - val_loss: 0.7554\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3115 - val_loss: 0.8388\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3181\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  28.9s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 4.3936 - val_loss: 13.3699\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.2098 - val_loss: 10.8972\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.4360 - val_loss: 7.7330\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0926 - val_loss: 5.0744\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9168 - val_loss: 3.2363\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8186 - val_loss: 2.1597\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7619 - val_loss: 1.4840\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7266 - val_loss: 1.1083\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7031 - val_loss: 0.8942\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6858 - val_loss: 0.7687\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6720 - val_loss: 0.6947\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6602 - val_loss: 0.6524\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6498 - val_loss: 0.6234\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6401 - val_loss: 0.6061\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6312 - val_loss: 0.5933\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6227 - val_loss: 0.5819\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6147 - val_loss: 0.5733\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6070 - val_loss: 0.5650\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5997 - val_loss: 0.5578\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5926 - val_loss: 0.5508\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5859 - val_loss: 0.5446\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5794 - val_loss: 0.5384\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5732 - val_loss: 0.5326\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5671 - val_loss: 0.5266\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5614 - val_loss: 0.5214\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5558 - val_loss: 0.5166\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5504 - val_loss: 0.5116\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5453 - val_loss: 0.5076\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5403 - val_loss: 0.5035\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5356 - val_loss: 0.4989\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5309 - val_loss: 0.4946\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5265 - val_loss: 0.4915\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5222 - val_loss: 0.4883\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5181 - val_loss: 0.4856\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5141 - val_loss: 0.4828\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5103 - val_loss: 0.4789\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5066 - val_loss: 0.4780\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5030 - val_loss: 0.4742\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4995 - val_loss: 0.4729\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4962 - val_loss: 0.4714\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4929 - val_loss: 0.4686\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4897 - val_loss: 0.4666\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4867 - val_loss: 0.4646\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4837 - val_loss: 0.4636\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4809 - val_loss: 0.4616\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4781 - val_loss: 0.4582\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4755 - val_loss: 0.4581\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4729 - val_loss: 0.4573\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4704 - val_loss: 0.4560\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4680 - val_loss: 0.4544\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4656 - val_loss: 0.4525\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4633 - val_loss: 0.4527\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4611 - val_loss: 0.4522\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4589 - val_loss: 0.4509\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4568 - val_loss: 0.4509\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4548 - val_loss: 0.4513\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4529 - val_loss: 0.4496\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4510 - val_loss: 0.4510\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4491 - val_loss: 0.4502\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4473 - val_loss: 0.4478\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4456 - val_loss: 0.4485\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4440 - val_loss: 0.4488\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4423 - val_loss: 0.4477\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4408 - val_loss: 0.4497\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4392 - val_loss: 0.4512\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4378 - val_loss: 0.4484\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4363 - val_loss: 0.4483\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4349 - val_loss: 0.4494\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4336 - val_loss: 0.4492\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4322 - val_loss: 0.4476\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4309 - val_loss: 0.4481\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4296 - val_loss: 0.4503\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4284 - val_loss: 0.4486\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4272 - val_loss: 0.4491\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4261 - val_loss: 0.4496\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4249 - val_loss: 0.4483\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4238 - val_loss: 0.4474\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4227 - val_loss: 0.4490\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4217 - val_loss: 0.4495\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4206 - val_loss: 0.4468\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4196 - val_loss: 0.4492\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4186 - val_loss: 0.4525\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4177 - val_loss: 0.4504\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4167 - val_loss: 0.4525\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4158 - val_loss: 0.4495\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4148 - val_loss: 0.4548\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4140 - val_loss: 0.4512\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4132 - val_loss: 0.4481\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4123 - val_loss: 0.4472\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4114 - val_loss: 0.4506\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4209\n",
            "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time= 1.4min\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.4569 - val_loss: 7.5238\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.5656 - val_loss: 8.6120\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0607 - val_loss: 8.4896\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8953 - val_loss: 7.7423\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8236 - val_loss: 6.8202\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7840 - val_loss: 5.9344\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7579 - val_loss: 5.1492\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7381 - val_loss: 4.4548\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7216 - val_loss: 3.9122\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7071 - val_loss: 3.4233\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6937 - val_loss: 2.9997\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6814 - val_loss: 2.6082\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6701 - val_loss: 2.2766\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6593 - val_loss: 1.9984\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6491 - val_loss: 1.7447\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6395 - val_loss: 1.5300\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6303 - val_loss: 1.3410\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6217 - val_loss: 1.1762\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6133 - val_loss: 1.0345\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6055 - val_loss: 0.9174\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5980 - val_loss: 0.8153\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5908 - val_loss: 0.7363\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5839 - val_loss: 0.6696\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5774 - val_loss: 0.6187\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5711 - val_loss: 0.5778\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5652 - val_loss: 0.5491\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5594 - val_loss: 0.5299\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5540 - val_loss: 0.5199\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5486 - val_loss: 0.5172\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5438 - val_loss: 0.5206\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5389 - val_loss: 0.5312\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5343 - val_loss: 0.5447\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5298 - val_loss: 0.5639\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5256 - val_loss: 0.5821\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5216 - val_loss: 0.6039\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5177 - val_loss: 0.6306\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5140 - val_loss: 0.6564\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5104 - val_loss: 0.6820\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5069 - val_loss: 0.7087\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5160\n",
            "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  24.5s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 4.0974 - val_loss: 7.4460\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.1844 - val_loss: 5.2071\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.4253 - val_loss: 2.9554\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0762 - val_loss: 1.7752\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9094 - val_loss: 1.1201\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8243 - val_loss: 0.8519\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7768 - val_loss: 0.7512\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7473 - val_loss: 0.7064\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7264 - val_loss: 0.6896\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7098 - val_loss: 0.6760\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6955 - val_loss: 0.6687\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6830 - val_loss: 0.6577\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6713 - val_loss: 0.6454\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6604 - val_loss: 0.6355\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6503 - val_loss: 0.6256\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6407 - val_loss: 0.6213\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6317 - val_loss: 0.6120\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6230 - val_loss: 0.6024\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6148 - val_loss: 0.5998\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6072 - val_loss: 0.5901\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5996 - val_loss: 0.5822\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5925 - val_loss: 0.5763\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5857 - val_loss: 0.5664\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5791 - val_loss: 0.5574\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5728 - val_loss: 0.5527\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5668 - val_loss: 0.5452\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5610 - val_loss: 0.5437\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5555 - val_loss: 0.5366\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5501 - val_loss: 0.5322\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5450 - val_loss: 0.5264\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5399 - val_loss: 0.5234\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5352 - val_loss: 0.5175\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5305 - val_loss: 0.5137\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5262 - val_loss: 0.5078\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5219 - val_loss: 0.5045\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5178 - val_loss: 0.4970\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5139 - val_loss: 0.4911\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5101 - val_loss: 0.4887\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5064 - val_loss: 0.4847\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5029 - val_loss: 0.4815\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4994 - val_loss: 0.4776\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4962 - val_loss: 0.4736\n",
            "Epoch 43/100\n",
            "213/242 [=========================>....] - ETA: 0s - loss: 0.4941"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-065a0ce42e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[1;32m     12\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                   callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         evaluate_candidates(\n\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m-> 1768\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m             )\n\u001b[1;32m   1770\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distribs = {\n",
        "    \"n_hidden\": [0, 1, 2, 3],\n",
        "    \"n_neurons\": np.arange(1, 100)               .tolist(),\n",
        "    \"learning_rate\": reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
        "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
        "                  validation_data=(X_valid, y_valid),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f47faae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f47faae",
        "outputId": "b916ebd6-5786-40e4-cc31-8fdf75429e85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.005803602934201024, 'n_hidden': 3, 'n_neurons': 74}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "rnd_search_cv.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b023aaf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b023aaf7",
        "outputId": "634b4c42-f54a-4d96-d712-8a74b829851b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.31959917147954303"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "rnd_search_cv.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "347a3ffe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "347a3ffe",
        "outputId": "44593616-3473-44d1-9fc2-ba061c90677e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.wrappers.scikit_learn.KerasRegressor at 0x7fc51538f150>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "rnd_search_cv.best_estimator_"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Lab9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}