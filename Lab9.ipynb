{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3b7edccd",
      "metadata": {
        "id": "3b7edccd"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib import cm\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#import numpy as np\n",
        "#from matplotlib import pyplot as plt\n",
        "#import seaborn as sns\n",
        "#%pylab inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 10"
      ],
      "metadata": {
        "id": "3hK7LxVXUCG4"
      },
      "id": "3hK7LxVXUCG4"
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "_bqTFWiCUA5p"
      },
      "id": "_bqTFWiCUA5p",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP_5mS7QUH_U",
        "outputId": "d76f71d3-c408-4363-fffd-f4cbd097c9b9"
      },
      "id": "BP_5mS7QUH_U",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255."
      ],
      "metadata": {
        "id": "m6C5U-1MUJlx"
      },
      "id": "m6C5U-1MUJlx",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[0], cmap=\"binary\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "wUcw0VpeULwj",
        "outputId": "6eec27e2-cde8-45bb-c90c-15ee53086aba"
      },
      "id": "wUcw0VpeULwj",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwYsCGePUNME",
        "outputId": "454ef46c-56f6-4e98-bedc-a6ab1544ec0a"
      },
      "id": "CwYsCGePUNME",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gskkILTnUPcx",
        "outputId": "5fc2c0c8-32b3-42bc-f40d-4a87b72f46a9"
      },
      "id": "gskkILTnUPcx",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_rows = 4\n",
        "n_cols = 10\n",
        "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
        "        plt.axis('off')\n",
        "        plt.title(y_train[index], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "ZB4vg3CLUQuo",
        "outputId": "c496d7cf-60e1-49f7-bf92-49d9123ca0cc"
      },
      "id": "ZB4vg3CLUQuo",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x345.6 with 40 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = keras.backend\n",
        "\n",
        "class ExponentialLearningRate(keras.callbacks.Callback):\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "        self.rates = []\n",
        "        self.losses = []\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
        "        self.losses.append(logs[\"loss\"])\n",
        "        K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)"
      ],
      "metadata": {
        "id": "AHlbGMODUV2H"
      },
      "id": "AHlbGMODUV2H",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "KeqGo_-NUWVj"
      },
      "id": "KeqGo_-NUWVj",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])\n",
        "expon_lr = ExponentialLearningRate(factor=1.005)"
      ],
      "metadata": {
        "id": "o2GGP4zPUakj"
      },
      "id": "o2GGP4zPUakj",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=1,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[expon_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2QkD8M9UrJ8",
        "outputId": "b2a0c01b-d1aa-47ea-f064-0a54f08c3948"
      },
      "id": "a2QkD8M9UrJ8",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1719/1719 [==============================] - 12s 7ms/step - loss: nan - accuracy: 0.5658 - val_loss: nan - val_accuracy: 0.0958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(expon_lr.rates, expon_lr.losses)\n",
        "plt.gca().set_xscale('log')\n",
        "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
        "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
        "plt.grid()\n",
        "plt.xlabel(\"Learning rate\")\n",
        "plt.ylabel(\"Loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "QEpf9K7CUro-",
        "outputId": "64d760ca-ba23-4528-d8b6-73a99d56fcb7"
      },
      "id": "QEpf9K7CUro-",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUZb7H8c9vUkghBQiEEHqvAhI6YqyLWBAVy9pXZV37eldd7+69u3rX7eraFbuugg0VG7iWUAVpAQREg7QEEOmEHnjuHxk0YoiZMWcmmfN9v17zYuacMzO/PCTznec85zzHnHOIiIh/BaJdgIiIRJeCQETE5xQEIiI+pyAQEfE5BYGIiM8pCEREfC4+2gWEKi4lw3Xv1I6EOGWYl3bu3Elqamq0y4h5aueatWTddjKTE2iWmfy95WpnmDt37kbnXOPK1tW5IIjPaMJL7xXQuWl6tEuJaQUFBeTn50e7jJindq5Zve58nxE9m3HHiO7fW652BjNbdaR1nn2tNrMWZvaxmS0xs8VmdmMl2+Sb2TYzKwze/rc6r71734GaL1hE6jydHxseL3sEZcB/OefmmVkaMNfM/uOcW3LYdlOdc6eF8sK79ysIRKRyZhbtEuocz3oEzrl1zrl5wfs7gKVAbk289h4FgYhUQlPmhCciYwRm1hroDcyqZPVAM1sArAV+45xbXMnzRwOjARKbtuc34+ZyT36KdwULpaWlFBQURLuMmKd2rlllZWWUlBRTUPDN95arnavmeRCYWX3gNeAm59z2w1bPA1o550rNbDjwBtDh8Ndwzo0BxgDUy+ngNu9xXDZxJ/P+5yQapiZ6/BP4kwbXIkPtXLPiCiaRm9uc/Pxu31uudq6ap8dgmlkC5SHwgnNu/OHrnXPbnXOlwfvvAglmllXVa2anJ317/+j/+0/NFiwidZ6GCELn5VFDBjwJLHXO3XOEbZoGt8PM+gXr2VTV6zauX4/+bRp++3h60Ua27NzHlC++4eBB7R8U8TV9BITFy11Dg4GLgUVmVhhc9t9ASwDn3KPAOcCvzKwM2A2c735ktMcMXvrlQEq27ub4fxZw4RPfDTsc0yGLBy84moyUBA9+HBGpCwx1CULlWRA456ZB1f8jzrkHgQfDef3czGQ+uPlY8v9ZwIGDjqOaZzD1y430vPN9/nZ2D07pkUNavXgdSibiI+oQhKfOnVlcUYuGKRTddQoHHcQFjBnLN3LtC/O47bVF3PbaIto1TuXGEztyWo8cAgEFgogf6Ltf6Op0EED5ySNxwf/4Qe2ymP27E/l05WY+WLKBCQtKuGHsfJ6ctoJLBrSiX5uGtGiow05FYpXOIwhPnQ+Cw8XHBRjULotB7bL43aldeLOwhLvf/4L/emUBAAPbNuK649szqF0j7TYSiUH6qw5dzAVBRXEB46yjm3Nmr1w+X7+Dj5dt4PlPVnHhE7No36Q+Q9pn8YvBbWjZSL0EkVig/kB4YjoIDgkEjK7N0unaLJ0rhrTh5TlreHfROl6ctZp/z1zF0I6NOfvo5pzYtQn14uOiXa6I/ATq6IfOF0FQUVJCHJcMbM0lA1vz9fY9PDVtBRMWrOXaF+eRmZLAiJ7NGJXXgu65GdEuVURCpCGC8PguCCrKTk/i9uFduHVYZ6YXbeTlOWsYO3sNz36yii456ZzeM4dj2jema7N04nTUkUidoLG/0Pk6CA6JCxhDOzZmaMfGbNu1nzcXlPDa3GL+PnEZf2cZDVISOPWoHEb2zuXolg30iyZSSzmNEoRFQXCYjJSEb3cdbdixh0+Wb+KDpRt4dW4x/565muz0epx9dHOGdW9K92YZOj9BpJbRX2ToFARVaJKWxIheuYzolcuOPfuZ+Nl63l20jsemfMXDBcvJTElgcPssTunelGM7NiYtSVNbiESTxgjCoyCoprSkBEbltWBUXgs2Bye5m1a0kYJlG3hn4ToS4wLkd2rMqLwW5HdqTEKcpxO7isiRqEsQMgVBGBqmJnJm71zO7J3LgYOOuau2MPGz9UxYUML7S74mq349RvZuxpm9c+mak64xBZEIUYcgPAqCnyguYPRr05B+bRpy+/DOFCz7hlfmrOHp6St5fOoKOjSpz6i85pzZO5cmaUk//oIi8pNo9tHQKQhqUEJcgJO6ZnNS12w2le5l4uL1vDq3mD+/+zl/m7iMwe2zOPvoXE7u2pTkRJ24JlLj1CUIi4LAI43q1+PC/q24sH8rijbsYPy8Et4sXMuN4wqpXy+eU7o35ayjm9O/TUMdeSRSg7QnNnQKggho3ySNW4d15jcnd+LTlZsZP6+Ydxet55W5xeRmJnNm72acfXRz2jauH+1SReo0nUcQHgVBBAUCxoC2jRjQthF3nNGd95esZ/y8Eh4pWM5DHy9naMfGXD64Ncd2aKxegkiY9JcTOgVBlCQnxn17jsKG7XsYN3sNz89cxeVPz6ZtViqXDmrN2X2aU7+e/otEqkvnEYRHB7vXAk3Sk7jhhA5Mv+147ju/F2nJCfxhwmIG/vlD7nxrCas27Yx2iSJ1hsYIQqevm7VIYnzg217C/NVbeHr6Sp77ZCVPz1jBCZ2b8Mtj29G3dcNolylSa6lDEB4FQS3Vu2UDerdswO9O7cILM1fxwqzVjHr0Ewa3b8RNJ3ZUIIgcgc4jCJ12DdVy2elJ3HxyJ6bddjy/P7ULy9bvYNSjn3DhEzOZvXJztMsTqVV0zeLwKAjqiOTEOK48pi1Tb/1+IFz0xCwK12yNdnkitYbGCEKnIKhjDg+EJeu2c+ZD0/nl83P44usd0S5PJKrUHwiPgqCOOhQIU249jl+f2JHpRZsY9q8p3D5+Id/s2Bvt8kSiRh2C0CkI6rj69eK58cQOTL31OC4d1JpX5hRz3D8LeKRgOXv2H4h2eSIRpSGC8CgIYkSD1ET+cHo3Jv16KAPaNuRvEz/npHsn8+6idRpAE3/RIEHIFAQxpl3j+jxxaV/+fUV/UhLiueaFeZz32EwWFW+LdmkiUkspCGLUkA5ZvHPDEO4a2Z3l35RyxkPT+M0rC9i8c1+0SxPxlPoDoVMQxLD4uAAX9m/Fx7fkM/qYtrxZWMLJ907hw6VfR7s0kRqnXaDhUxD4QHpSArcP78Kb1w4hq34iVzw7h1teWcDWXeodSOzREEHoFAQ+0rVZOm9eN5hr8tsxfn4JJ94zmQkL1uqblMQE/RqHT0HgM/Xi47h1WGfeum4IuZnJ3DB2Plc9N5d123ZHuzSRGqG5hkLnWRCYWQsz+9jMlpjZYjO7sZJtzMzuN7MiM1toZkd7VY98X9dm6Yy/ZjC/G96FaUXfcPI9U3izsCTaZYmETR2C8HnZIygD/ss51xUYAFxrZl0P2+YUoEPwNhp4xMN65DBxAeOqoW2ZdNNQOjVN48Zxhfz6pUJ27Nkf7dJEwqYxgtB5FgTOuXXOuXnB+zuApUDuYZuNAJ5z5WYCmWaW41VNUrlWjVIZN3oAN53YgTcLSxh+/1SKtuisZBG/iMj1CMysNdAbmHXYqlxgTYXHxcFl6w57/mjKewxkZ2dTUFDgUaX+1isebu+XxGML9/DnWQf5Ysv7DGuTQEBfsTxTWlqq3+cacuBg+c6hFStWUFDw/d2caueqeR4EZlYfeA24yTm3PZzXcM6NAcYA5OXlufz8/JorUL4nHzjvlP384pEPefmL/WwKNOCec3uRkZIQ7dJiUkFBAfp9rhllBw7C++/Rtk0b8vM7fG+d2rlqnh41ZGYJlIfAC8658ZVsUgK0qPC4eXCZRFF6UgLX9qrHH0/vypQvv+H0B6exZG1YGS4SMRosDp+XRw0Z8CSw1Dl3zxE2mwBcEjx6aACwzTm37gjbSgSZGZcNbsO40QPZW3aAsx6ZzlsL1ka7LJEfpT2ZofOyRzAYuBg43swKg7fhZna1mV0d3OZd4CugCHgcuMbDeiQMfVo14O3rj6FHbgbXj53PX9/7/Nt9sSK1iU4oC59nYwTOuWn8yPxPrvyU1mu9qkFqRuO0erxw5QDueGsxj05ezufrt3Pf+b3JSNa4gdQ+pi5ByHRmsVRLYnyAu0b24K6R3ZletJEzH5pO0QZdGlNqD6dRgrApCCQkF/ZvxYtXDWDHnv2c+dAMPliimUxF6joFgYSsb+uGTLhuCK2zUrjyuTn8ccJidu/TCWgSXRojCJ+CQMLSLDOZV68exGWDWvPMjJWMfHg6azbvinZZIjpqKAwKAglbUkIcfzyjG09f3peSrbsZ8dB0Pl2xOdpliUiIFATykx3XqQlvXDuYzOQEfv74TJ6evkLXOJCo0TTUoVMQSI1o17g+r187mPxOTbjjrSXcOK5Q4wYSUfruET4FgdSYjOQExlzch1t+1om3Fq7l7EdmaNxAIk5jBKFTEEiNCgSMa49rz1OX9mXNll2cev9UJn62PtpliQ/oPILwKQjEE8d1bsI71x9D66xUrv73XP709pLy2SFFPKYOQegUBOKZlo1SePXqQVw6sBVPTFvBRU/OYmPp3miXJTFKYwThUxCIpxLjA9wxojv3nNuT+au3ctr905i/eku0y5IYpjGC0CkIJCLOOro5468ZREK8cd5jM3lx1modYio1Sr9N4VMQSMR0a5bBW9cNYWC7Rvz364u47bWF7NmvQ0ylZuk8gtApCCSiMlMSeeqyvtxwfHtenlPMqEc/oXiLDjGVn049zPApCCTi4gLGzSd34vFL8li5cSenPzCNyV98E+2yJEZojCB0CgKJmpO6ZvPmdYPJTk/isqc/5d7/fKGrn0nY9JsTPgWBRFXbxvV5/ZrBjOydy30ffsllT3/KJh1iKhJRCgKJuuTEOO4e1ZO/ntWDWSs2c9oD05i7SoeYSmg0RBA+BYHUCmbG+f1aMv5Xg0iIC3DeY58wZspyDmpXkYRI1ywOnYJAapXuuRm8df0QTujShD+/+zmXPzNbZyNL9eg7Q9gUBFLrZCQn8OhFffi/M7vzyVebOOW+qUwv2hjtsqSOUH8gdAoCqZXMjIsHtOLNaweTkZzARU/O4h+TPtfEdXJEmn00fAoCqdW65KQz4brBnNunBQ99vJzzxszUCWhSJQ0RhE5BILVeSmI8fzvnKO6/oDfL1u9g+H1TmfjZumiXJbWMjhoKn4JA6owzejbjnRuG0CYrlav/PY/fv7FIcxXJD6hDEDoFgdQprRql8srVgxg9tC3/nrma4fdNZZ6mtRZ00NBPoSCQOicxPsB/D+/CC1f2Z2/ZQc55ZAZ/eW+pegcC6DyCcCgIpM4a3D6LiTcdw3l9W/DY5K84/YFpLCzeGu2yJEo0+2j4FARSp6UlJfCXs47i2V/0Y8eeMkY+PIO731/GvjIdZupX6hCETkEgMeHYjo2Z9OuhjOydywMfFXHGg9P4rGRbtMuSCFJ/IHwKAokZGckJ/HNUT568NI9NO/cx4qHp/H3i5xo78Bl1CEKnIJCYc0KXbD749bGM7J3LwwXLOeneybrwjQ9oiCB8ngWBmT1lZhvM7LMjrM83s21mVhi8/a9XtYj/ZKSU9w5evKo/9eLjuPSpT7nllQVs3rkv2qWJ1zRIEDIvewTPAMN+ZJupzrlewdudHtYiPjWoXRZvXz+EX+W34/X5JRx/dwFjP12t6a1jkOYaCp9nQeCcmwJs9ur1RaorKSGO24Z15r0bj6FTdhq3j1/EWY/M0GByjFJ/IHTRHiMYaGYLzOw9M+sW5VokxnXITmPc6AHce15Pirfs4owHp/HHCYvZvmd/tEuTmqAOQdjMy5MwzKw18LZzrnsl69KBg865UjMbDtznnOtwhNcZDYwGyM7O7jNu3DjPapZypaWl1K9fP9pleGbnfsf4L/fx0eoy0usZF3RKpH9OXMTPSo31do6krXsOclPBbi7tmshxLRO+t07tDMcdd9xc51xeZeuiFgSVbLsSyHPOVXkFkry8PDdnzpwaqU+OrKCggPz8/GiX4bmFxVv5nzc+Y0HxNga1a8TvT+1K12bpEXt/v7RzJGzYvod+f/6Qu0Z258L+rb63Tu0MZnbEIIjariEza2rBr19m1i9Yy6Zo1SP+dFTzTMZfM5g/ndmdJeu2c+oDU7n55UJKtu6OdmkSIu0ZCl+8Vy9sZmOBfCDLzIqBPwAJAM65R4FzgF+ZWRmwGzjfabIQiYK4gHHRgFacflQzHp5cxNPTV/L2wnVcMaQNv8pvR3pSwo+/iNQapuHikHkWBM65C35k/YPAg169v0ioMlISuP2ULlwysDV3T1rGIwXLeWn2Gq7Jb8dFA1qRlBAX7RKlCofml4qPUxCEKtpHDYnUOrmZydxzXi/eum4I3Zql86d3lnL8Pwt4efYaXTO5Ftu1r3wqkdREz77fxiwFgcgR9GiewfNX9OeFK/uTlVaPW19byAn3TObVucUKhFpo574yAFLqqecWKgWByI8Y3D6LN68dzOOX5FG/Xjy/eWUBJ907hfHzijmgM5RrjV171SMIl4JApBrMjJO6ZvP29UN47OI+JCXEcfPLCzjpnsm8WViiQKgFDs0ym5Sgj7VQqcVEQmBm/KxbU965fgiPXHg0CXEBbhxXyM/+NYUJC9YqEKLoQPCgw4AmnQtZtYLAzFLNLBC839HMzjAzHVMnvhUIGKf0yOG9G4/hoZ8fTcDghrHzGfavKby9cK0mtYuCQ0efxwUUBKGqbo9gCpBkZrnA+8DFlM8uKuJrgYBx6lE5TLxxKA9c0BsHXPfifE65bypvzC9hvwaVI+ZQ9qpHELrqBoE553YBZwEPO+dGAZokTiQoEDBO79mMSTcN5b7ze3HQOW56qZD8fxTw+JSv2LZLE9t57dBuOXUIQlftIDCzgcCFwDvBZTpGS+QwcQFjRK9cJt00lCcvzSM3M5m73l3KgL98yG9fW6iprz10MLhrKNITB8aC6h5ndRNwO/C6c26xmbUFPvauLJG6LRAwTuiSzQldslm8dhvPf7KKNwpLGDd7DT1bZHLxgFacdlROtMuMKYcmqNEYQeiqFQTOucnAZIDgoPFG59wNXhYmEiu6Ncvgr2cfxe3Du/D6vGKen7mK37yygD+9s4SB2dC2xy5aNkqJdpl1nnYNha+6Rw29aGbpZpYKfAYsMbNbvC1NJLZkJCdw2eA2fHDzsbx4VX8GtWvEpJX7OfafH3P505/y4dKvdfjpT3BQh4+Grbq7hro657ab2YXAe8BvgbnAPzyrTCRGmRmD2mUxqF0Wr0/8iBWBXMbOXsMVz84hNzOZ8/u24Ly+LWiSnhTtUuuUQ7uGAuoShKy6QZAQPG/gTOBB59x+M9NXF5GfqEFSgJH5nbj+hA58sORrXpi1mrv/8wX3ffglJ3fL5sL+rRjYtpE+3KrhuxPKolxIHVTdIHgMWAksAKaYWStgu1dFifhNQlyAU3rkcEqPHFZs3MmLs1bxytxi3l20njZZqfy8X0vO6dOcBqmJ0S611tKuofBVa4zAOXe/cy7XOTfclVsFHOdxbSK+1CYrld+d2pWZt5/Avef1pFFqIne9u5T+f/mQX79UyJyVm9E1nH5IJ5SFr1o9AjPLoPwKY0ODiyYDdwI6KFrEI0kJcYzs3ZyRvZvz+frtvDhrNePnlfD6/BI6ZaeR17oBx3TIIr9TE100h++mmNCuodBVd9fQU5QfLXRu8PHFwNOUn2ksIh7r3DSdO0d057ZhnXlrwVrGzV7DhAVreWHWatKS4jm9ZzNG9WlOrxaZvj2h6rvDR/358/8U1Q2Cds65sys8vsPMCr0oSESOLLVePOf3a8n5/VpSduAgM5Zv4vX5JYyfV8yLs1bTqlEKZ/RsxohezWjfJC3a5UbUQR01FLbqBsFuMxvinJsGYGaDKb/gvIhESXxcgKEdGzO0Y2PuGNGNiYvWM2HBWh76uIgHPiqiS046px2Vw7DuTWnXuH60y/Wcdg2Fr7pBcDXwXHCsAGALcKk3JYlIqNKTEji3bwvO7duCDTv28M7CdUxYsJZ/TFrGPyYto13jVH7WrSk/69aUo5pnxOTuI+0aCl91p5hYAPQ0s/Tg4+1mdhOw0MviRCR0TdKSuHxwGy4f3IZ123bz/uKvmbR4PY9N+YqHC5aTm5nMqUflcPpRzeiemx4zoXBQcw2FLaSLezrnKp47cDPwr5otR0RqUk5GMpcOas2lg1qzZec+Pvx8A+8sXMtT01YwZspXtGqUwvAeOQyLgZ7Cd7OPRrmQOuinXOVZzS1ShzRITeScPs05p09ztu7ax6TF63l74TrGTPmKRwqWk5ORxM+6NeXkbtnktWpIYnzdupLtQe0aCttPCQKd0SJSR2WmJHJe35ac17clW3ft44OlG5i0eD1jP13NMzNWkpIYR/82DRncPoshHbLolJ1W63sLumZx+KoMAjPbQeUf+AYke1KRiERUZsp3PYVd+8qY+uVGphdtZFrRRj5+ZykAWfXrMbh9Iwa3z2Jw+yxyM2vfn//ufQdIjA9ojCAMVQaBc85fByKL+FxKYvy3RxcBrN26m+lFG5mxfBPTijbyZuFaANpmpQZDoRED22aRkZIQzbIB2LG3jPSkn7KTw7/UaiJyRM0ykxmV14JReS1wzvHlhlKmBXsM44MX2QkY9MjNKN+N1D6L3i0bkJwY+SkvSveUUb+ePtLCoVYTkWoxMzpmp9ExO41fDGnD/gMHWbBmK9OKyoNhTPDw1ICVT4kxqF0jBrVvRN/WDUlL8r7H8M2OvZqdNUwKAhEJS0JcgLzWDclr3ZCbTuxI6d4yPl2xicI12/h0xSaem7mKJ6atIC5gdM1J56jmGfRu2YD+bRrSLDO5Rvfll+4tY/bKzZx9dPMae00/URCISI2oXy+e4ztnc3znbAD27D/AvFVbmLF8E3NXbWFCYfkkeQAJcUaP3AySE+Po0CSNPq0a0CUnnWaZSaQkhv6xtHTddsoOOoZ0yKrRn8kvFAQi4omkhDgGtc9iUPvyD+eDBx1fbNjB7BWbWb15F4VrtlK6p4yXZq/hmRkrv31em6xUerfMpHeLTHq1aEDnnDQS4qo+p+GDpV8D0Ld1Q89+nlimIBCRiAgEjM5N0+ncNP17y/cfOMiy9Tv44usdlGzZzYLibUz54hvGzysBID5gtGyYQrfcDNpmpdIxO41OTdNolJrIjj1l5GQmMe3LjfRr3ZCmGbrOczisrl3pKC0tzfXp0yfaZcS8rVu3kpmZGe0yYp7auXIOKKuXzr76OexLacz+5Cz2pjbhQGL6EeeQaLDyIzLWz610ndoZJk+ePNc5l1fZOs96BGb2FHAasME5172S9QbcBwwHdgGXOefmeVWPiNQdBiTs3U7C3u2kblr27fKDFsf+lCz2JzfiQHwygQP7KEvKxFkcaRs0B2a4vNw19AzwIPDcEdafAnQI3voDjwT/rVKnTp0oKCiomQrliAoKCsjPz492GTFP7RwZameqnCLEs1mlnHNTgM1VbDICeM6VmwlkmlmOV/WIiEjlojlYnAusqfC4OLhs3eEbmtloYDRAdna2egQRUFpaqnaOALVzZKidq1Ynjhpyzo0BxgDk5eU5v3fxIkFd6chQO0eG2rlq0ZxwvARoUeFx8+AyERGJoGgGwQTgEis3ANjmnPvBbiEREfGWl4ePjgXygSwzKwb+ACQAOOceBd6l/NDRIsoPH73cq1pEROTIPAsC59wFP7LeAdd69f4iIlI9deuipCIiUuMUBCIiPqcgEBHxOQWBiIjPKQhERHxOQSAi4nMKAhERn1MQiIj4nIJARMTnFAQiIj6nIBAR8TkFgYiIzykIRER8TkEgIuJzCgIREZ9TEIiI+JyCQETE5xQEIiI+pyAQEfE5BYGIiM8pCEREfE5BICLicwoCERGfUxCIiPicgkBExOcUBCIiPqcgEBHxOQWBiIjPKQhERHxOQSAi4nMKAhERn1MQiIj4nIJARMTnPA0CMxtmZsvMrMjMflvJ+svM7BszKwzervSyHhER+aF4r17YzOKAh4CTgGJgtplNcM4tOWzTl5xz13lVh4iIVM3LHkE/oMg595Vzbh8wDhjh4fuJiEgYvAyCXGBNhcfFwWWHO9vMFprZq2bWwsN6RESkEp7tGqqmt4Cxzrm9ZvZL4Fng+MM3MrPRwGiA7OxsCgoKIlqkH5WWlqqdI0DtHBlq56p5GQQlQMVv+M2Dy77lnNtU4eETwN8reyHn3BhgDEBeXp7Lz8+v0ULlhwoKClA7e0/tHBlq56p5uWtoNtDBzNqYWSJwPjCh4gZmllPh4RnAUg/rERGRSnjWI3DOlZnZdcAkIA54yjm32MzuBOY45yYAN5jZGUAZsBm4zKt6RESkcp6OETjn3gXePWzZ/1a4fztwu5c1iIhI1XRmsYiIzykIRER8TkEgIuJzCgIREZ9TEIiI+JyCQETE5xQEIiI+pyAQEfE5BYGIiM8pCEREfE5BICLicwoCERGfUxCIiPicgkBExOcUBCIiPqcgEBHxOQWBiIjPKQhERHxOQSAi4nMKAhERn1MQiIj4nIJARMTnFAQiIj6nIBAR8TkFgYiIzykIRER8TkEgIuJzCgIREZ9TEIiI+JyCQETE5xQEIiI+pyAQEfE5BYGIiM8pCEREfM7TIDCzYWa2zMyKzOy3layvZ2YvBdfPMrPWXtYjIiI/5FkQmFkc8BBwCtAVuMDMuh622RXAFudce+Be4G9e1SMiIpXzskfQDyhyzn3lnNsHjANGHLbNCODZ4P1XgRPMzDysSUREDhPv4WvnAmsqPC4G+h9pG+dcmZltAxoBGytuZGajgdHBh6VmtsyTin8oA9gWoedXZ9uqtjnSusqWV2dZFof9P3hI7RwZaufIqK3t3OqIWzjnPLkB5wBPVHh8MfDgYdt8BjSv8Hg5kOVVTWH8DGMi9fzqbFvVNkdaV9ny6iwD5qid1c5q59hu50M3L3cNlQAtKjxuHlxW6TZmFk95cm3ysKZQvRXB51dn26q2OdK6ypZXd1mkqJ0jQ+0cGXWpnQGwYGLUuOAH+xfACZR/4M8Gfu6cW1xhm2uBHs65q83sfOAs59y5nhQkITGzOc65vGjXEevUzpGhdq6aZ2MErnyf/3XAJCAOeMo5t9jM7qS8mzYBeBJ43syKgM3A+V7VIyEbE+0CfELtHBlq5yp41iMQEZG6QWcWiyAb2MMAAASISURBVIj4nIJARMTnFAQiIj6nIJCQmdmZZvZ4cJ6ok6NdT6wys7Zm9qSZvRrtWmKNmaWa2bPB3+MLo11PtCkIfMbMnjKzDWb22WHLq5wgsCLn3BvOuauAq4HzvKy3rqqhdv7KOXeFt5XGjhDb/Czg1eDv8RkRL7aWURD4zzPAsIoLjjRBoJn1MLO3D7s1qfDU3wefJz/0DDXXzlI9z1DNNqf8BNdDU+AciGCNtZKXcw1JLeScm1LJdN/fThAIYGbjgBHOub8Apx3+GsGJAf8KvOecm+dtxXVTTbSzhCaUNqd87rPmQCH6QqwGEKDyCQJzq9j+euBE4Bwzu9rLwmJMSO1sZo3M7FGgt5nd7nVxMepIbT4eONvMHiG601HUCuoRSMicc/cD90e7jljnnNtE+TiM1DDn3E7g8mjXUVuoRyBQvQkC5adTO0ee2rwaFAQC5RMCdjCzNmaWSPmcTxOiXFMsUjtHntq8GhQEPmNmY4FPgE5mVmxmVzjnyoBDEwQuBV6uOEushE7tHHlq8/Bp0jkREZ9Tj0BExOcUBCIiPqcgEBHxOQWBiIjPKQhERHxOQSAi4nMKAokZZlYa4febEeH3yzSzayL5nuIPCgKRIzCzKufics4NivB7ZgIKAqlxCgKJaWbWzswmmtlcM5tqZp2Dy083s1lmNt/MPjCz7ODyP5rZ82Y2HXg++PgpMysws6/M7IYKr10a/Dc/uP5VM/vczF4ITtWNmQ0PLptrZveb2duV1HiZmU0ws4+AD82svpl9aGbzzGyRmY0IbvpXoJ2ZFZrZP4LPvcXMZpvZQjO7w8u2lBjmnNNNt5i4AaWVLPsQ6BC83x/4KHi/Ad+dWX8lcHfw/h+BuUByhcczgHpAFrAJSKj4fkA+sI3yCc0ClE9zMARIonwK5DbB7cYCb1dS42WUT4/cMPg4HkgP3s8CigADWgOfVXjeycCY4LoA8DYwNNr/D7rVvZumoZaYZWb1gUHAK8Ev6FD+gQ7lH9ovmVkOkAisqPDUCc653RUev+Oc2wvsNbMNQDblH9wVfeqcKw6+byHlH9qlwFfOuUOvPRYYfYRy/+Oc23yodODPZjYUOEj5/PnZlTzn5OBtfvBxfaADMOUI7yFSKQWBxLIAsNU516uSdQ8A9zjnJphZPuXf/A/Zedi2eyvcP0DlfzfV2aYqFd/zQqAx0Mc5t9/MVlLeuzicAX9xzj0W4nuJfI/GCCRmOee2AyvMbBSUX2LTzHoGV2fw3bz0l3pUwjKgbYXLJ55XzedlABuCIXAc0Cq4fAeQVmG7ScAvgj0fzCxX1zqWcKhHILEkxcwq7rK5h/Jv14+Y2e+BBGAcsIDyHsArZrYF+AhoU9PFOOd2Bw/3nGhmOymfG786XgDeMrNFwBzg8+DrbTKz6Wb2GeXXi77FzLoAnwR3fZUCFwEbavpnkdimaahFPGRm9Z1zpcGjiB4CvnTO3RvtukQq0q4hEW9dFRw8Xkz5Lh/tz5daRz0CERGfU49ARMTnFAQiIj6nIBAR8TkFgYiIzykIRER8TkEgIuJz/w+hhGFcFJZ7JQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "5yrtcIUCUtZG"
      },
      "id": "5yrtcIUCUtZG",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=3e-1),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "-sokvAQVU1Hc"
      },
      "id": "-sokvAQVU1Hc",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "run_index = 1 # increment this at every run\n",
        "run_logdir = os.path.join(os.curdir, \"my_mnist_logs\", \"run_{:03d}\".format(run_index))\n",
        "run_logdir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oC2-hohaU1mW",
        "outputId": "4cedbb78-ff63-4e89-babb-595e6faf773b"
      },
      "id": "oC2-hohaU1mW",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./my_mnist_logs/run_001'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzkYZDt3U3PZ",
        "outputId": "9de7ac7a-ab79-4936-a59f-535131afb2ce"
      },
      "id": "OzkYZDt3U3PZ",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2362 - accuracy: 0.9266 - val_loss: 0.0978 - val_accuracy: 0.9704\n",
            "Epoch 2/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0946 - accuracy: 0.9703 - val_loss: 0.0926 - val_accuracy: 0.9730\n",
            "Epoch 3/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0664 - accuracy: 0.9787 - val_loss: 0.0827 - val_accuracy: 0.9756\n",
            "Epoch 4/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0476 - accuracy: 0.9850 - val_loss: 0.0750 - val_accuracy: 0.9790\n",
            "Epoch 5/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0354 - accuracy: 0.9880 - val_loss: 0.0788 - val_accuracy: 0.9784\n",
            "Epoch 6/100\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.0300 - accuracy: 0.9904 - val_loss: 0.0768 - val_accuracy: 0.9794\n",
            "Epoch 7/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0807 - val_accuracy: 0.9796\n",
            "Epoch 8/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0716 - val_accuracy: 0.9818\n",
            "Epoch 9/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0208 - accuracy: 0.9927 - val_loss: 0.0931 - val_accuracy: 0.9800\n",
            "Epoch 10/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.0783 - val_accuracy: 0.9844\n",
            "Epoch 11/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.0847 - val_accuracy: 0.9838\n",
            "Epoch 12/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0891 - val_accuracy: 0.9814\n",
            "Epoch 13/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.0878 - val_accuracy: 0.9824\n",
            "Epoch 14/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.1087 - val_accuracy: 0.9812\n",
            "Epoch 15/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1000 - val_accuracy: 0.9806\n",
            "Epoch 16/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0864 - val_accuracy: 0.9836\n",
            "Epoch 17/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0862 - val_accuracy: 0.9854\n",
            "Epoch 18/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 4.9891e-04 - accuracy: 0.9999 - val_loss: 0.0833 - val_accuracy: 0.9866\n",
            "Epoch 19/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 1.3572e-04 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9860\n",
            "Epoch 20/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 7.4768e-05 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9872\n",
            "Epoch 21/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 6.0104e-05 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9872\n",
            "Epoch 22/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 5.2219e-05 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9872\n",
            "Epoch 23/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 4.6609e-05 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9872\n",
            "Epoch 24/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 4.2480e-05 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9872\n",
            "Epoch 25/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9197e-05 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9872\n",
            "Epoch 26/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 3.6543e-05 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9872\n",
            "Epoch 27/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4127e-05 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9872\n",
            "Epoch 28/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 3.2038e-05 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_mnist_model.h5\") # rollback to best model\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMArfl96U5UL",
        "outputId": "65da43a3-3dea-4b97-b6b8-4e61c65a5f56"
      },
      "id": "sMArfl96U5UL",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0830 - accuracy: 0.9809\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08301407098770142, 0.98089998960495]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a941fa14",
      "metadata": {
        "id": "a941fa14"
      },
      "source": [
        "## Hyperparameter Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96eb8439",
      "metadata": {
        "id": "96eb8439"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e03921ba",
      "metadata": {
        "id": "e03921ba"
      },
      "outputs": [],
      "source": [
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27116836",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27116836",
        "outputId": "c872a80c-67db-4d15-9fc0-2c0dfc7bb0a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e76d264",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e76d264",
        "outputId": "ff74ff95-cdb4-413e-a8c7-003be0bbc475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 1.0896 - val_loss: 20.7721\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7606 - val_loss: 5.0266\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5456 - val_loss: 0.5490\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4732 - val_loss: 0.4529\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4503 - val_loss: 0.4188\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4338 - val_loss: 0.4129\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4241 - val_loss: 0.4004\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4168 - val_loss: 0.3944\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4108 - val_loss: 0.3961\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4060 - val_loss: 0.4071\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4021 - val_loss: 0.3855\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3984 - val_loss: 0.4136\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.3997\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3921 - val_loss: 0.3818\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3894 - val_loss: 0.3829\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.3739\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3848 - val_loss: 0.4022\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.3873\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3807 - val_loss: 0.3768\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3791 - val_loss: 0.4191\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3774 - val_loss: 0.3927\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.4237\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3523\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3725 - val_loss: 0.3842\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.4162\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.3980\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.3474\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.3920\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3670 - val_loss: 0.3566\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3653 - val_loss: 0.4191\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.3721\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3633 - val_loss: 0.3948\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3632 - val_loss: 0.3423\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3617 - val_loss: 0.3453\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.4068\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.3417\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3596 - val_loss: 0.3787\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3379\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3419\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3705\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3570 - val_loss: 0.3659\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3563 - val_loss: 0.3803\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3552 - val_loss: 0.3765\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 0.3813\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3543 - val_loss: 0.3326\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3532 - val_loss: 0.3385\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.3655\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3521 - val_loss: 0.3579\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.3360\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3510 - val_loss: 0.3317\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3504 - val_loss: 0.3562\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3502 - val_loss: 0.3521\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.4579\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3497 - val_loss: 0.3809\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3540\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3485 - val_loss: 0.3725\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3478 - val_loss: 0.3337\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3469 - val_loss: 0.4011\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3476 - val_loss: 0.3263\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.3271\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3453 - val_loss: 0.3349\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3454 - val_loss: 0.3541\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.3428\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3451 - val_loss: 0.3280\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3437 - val_loss: 0.3292\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3301\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3428 - val_loss: 0.3254\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.3245\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3419 - val_loss: 0.3255\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3413 - val_loss: 0.3666\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3414 - val_loss: 0.3370\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3405 - val_loss: 0.3267\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3400 - val_loss: 0.3245\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3402 - val_loss: 0.3663\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3397 - val_loss: 0.3290\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3395 - val_loss: 0.3235\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3386\n",
            "Epoch 78/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3384 - val_loss: 0.3362\n",
            "Epoch 79/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3384 - val_loss: 0.3222\n",
            "Epoch 80/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3376 - val_loss: 0.3644\n",
            "Epoch 81/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3384 - val_loss: 0.3420\n",
            "Epoch 82/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3371 - val_loss: 0.3253\n",
            "Epoch 83/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3368 - val_loss: 0.3246\n",
            "Epoch 84/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3362 - val_loss: 0.3953\n",
            "Epoch 85/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3372 - val_loss: 0.3415\n",
            "Epoch 86/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3359 - val_loss: 0.3190\n",
            "Epoch 87/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3356 - val_loss: 0.3277\n",
            "Epoch 88/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3351 - val_loss: 0.3295\n",
            "Epoch 89/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3348 - val_loss: 0.3247\n",
            "Epoch 90/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3344 - val_loss: 0.3281\n",
            "Epoch 91/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3341 - val_loss: 0.3201\n",
            "Epoch 92/100\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3338 - val_loss: 0.3393\n",
            "Epoch 93/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3336 - val_loss: 0.3170\n",
            "Epoch 94/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3334 - val_loss: 0.3526\n",
            "Epoch 95/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3329 - val_loss: 0.4813\n",
            "Epoch 96/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3339 - val_loss: 0.3465\n",
            "Epoch 97/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3324 - val_loss: 0.4632\n",
            "Epoch 98/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3333 - val_loss: 0.6725\n",
            "Epoch 99/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3330 - val_loss: 0.5924\n",
            "Epoch 100/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3343 - val_loss: 0.5272\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc5157c4f50>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "keras_reg.fit(X_train, y_train, epochs=100,\n",
        "              validation_data=(X_valid, y_valid),\n",
        "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50733161",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50733161",
        "outputId": "1a364c4d-9eeb-4398-a519-d1ab5534c245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 1ms/step - loss: 0.3346\n"
          ]
        }
      ],
      "source": [
        "mse_test = keras_reg.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "092b97ad",
      "metadata": {
        "id": "092b97ad"
      },
      "outputs": [],
      "source": [
        "y_pred = keras_reg.predict(X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d40289cb",
      "metadata": {
        "id": "d40289cb"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ac8fd18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ac8fd18",
        "outputId": "09c598fc-2d11-4a0f-bd2d-a522fcd23c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8420 - val_loss: 0.4703\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4815 - val_loss: 0.4247\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4519 - val_loss: 0.4052\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4429 - val_loss: 0.3975\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4368 - val_loss: 0.3991\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4340 - val_loss: 0.4031\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4351 - val_loss: 0.4043\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4267 - val_loss: 0.3929\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4258 - val_loss: 0.4040\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4237 - val_loss: 0.3886\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4209 - val_loss: 0.3999\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.4085\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4139 - val_loss: 0.3922\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4132 - val_loss: 0.3918\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4106 - val_loss: 0.3886\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4092 - val_loss: 0.3933\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4092 - val_loss: 0.3907\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4087 - val_loss: 0.3955\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4058 - val_loss: 0.3935\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4053 - val_loss: 0.3891\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4251\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  11.7s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7452 - val_loss: 0.4860\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4649 - val_loss: 0.4280\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4495 - val_loss: 0.5791\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4438 - val_loss: 0.4549\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4414 - val_loss: 0.5250\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4409 - val_loss: 0.5486\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4388 - val_loss: 0.5871\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4381 - val_loss: 0.4759\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4371 - val_loss: 0.7523\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4369 - val_loss: 0.7478\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4344 - val_loss: 0.8981\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4347 - val_loss: 0.8543\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4537\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   7.4s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 10.8725 - val_loss: 4.2468\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0257 - val_loss: 0.5794\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5263 - val_loss: 0.4357\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4640 - val_loss: 0.4169\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4515 - val_loss: 0.4135\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4486 - val_loss: 0.4206\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4567 - val_loss: 0.4100\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4495 - val_loss: 0.4155\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4111\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4620 - val_loss: 0.4076\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4470 - val_loss: 0.4062\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4460 - val_loss: 0.4078\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4462 - val_loss: 0.4160\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4445 - val_loss: 0.4158\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4430 - val_loss: 0.4137\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4515 - val_loss: 0.4069\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4422 - val_loss: 0.4119\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4408 - val_loss: 0.4149\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4429 - val_loss: 0.4081\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4595 - val_loss: 0.4141\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4431 - val_loss: 0.4100\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4473\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  21.1s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1684 - val_loss: 6.2480\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6285 - val_loss: 5.2166\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5212 - val_loss: 0.4474\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4280 - val_loss: 0.3901\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4008 - val_loss: 0.3736\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3840 - val_loss: 0.3803\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3730 - val_loss: 0.3813\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3648 - val_loss: 0.3961\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3591 - val_loss: 0.3988\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3542 - val_loss: 0.3891\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3510 - val_loss: 0.3870\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3769\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3424 - val_loss: 0.3770\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3407 - val_loss: 0.3848\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3371 - val_loss: 0.3769\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3561\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  10.9s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8828 - val_loss: 3.5738\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4887 - val_loss: 0.7767\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4267 - val_loss: 0.5515\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4011 - val_loss: 0.5335\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3852 - val_loss: 0.5336\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3746 - val_loss: 0.6750\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3678 - val_loss: 0.8462\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3610 - val_loss: 0.8724\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3554 - val_loss: 0.9645\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.7225\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3475 - val_loss: 0.7257\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3442 - val_loss: 0.7217\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3422 - val_loss: 0.8443\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3407 - val_loss: 0.7065\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3650\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  11.0s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0015 - val_loss: 2.9433\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5546 - val_loss: 4.2557\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4854 - val_loss: 2.8526\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4594 - val_loss: 1.6798\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4136 - val_loss: 0.4322\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3937 - val_loss: 0.4172\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3829 - val_loss: 0.3769\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3753 - val_loss: 0.3688\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3692 - val_loss: 0.4032\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3655 - val_loss: 0.3418\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3610 - val_loss: 0.4452\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.3454\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3526 - val_loss: 0.3395\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3503 - val_loss: 0.4354\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3489 - val_loss: 0.3386\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.4038\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3434 - val_loss: 0.3302\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3406 - val_loss: 0.3580\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3386 - val_loss: 0.3546\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3360 - val_loss: 0.3460\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3355 - val_loss: 0.3244\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.3257\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3315 - val_loss: 0.3441\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3301 - val_loss: 0.3377\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3289 - val_loss: 0.3651\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3271 - val_loss: 0.3924\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3256 - val_loss: 0.3141\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3237 - val_loss: 0.3201\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3250 - val_loss: 0.4308\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3232 - val_loss: 0.3204\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3196 - val_loss: 0.3129\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3177 - val_loss: 0.4282\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3187 - val_loss: 0.3116\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3152 - val_loss: 0.3920\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3173 - val_loss: 0.4133\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3138 - val_loss: 0.6989\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3161 - val_loss: 0.7475\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3227 - val_loss: 1.0271\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3186 - val_loss: 0.4150\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3119 - val_loss: 0.6728\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3126 - val_loss: 0.3501\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3079 - val_loss: 0.7554\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3115 - val_loss: 0.8388\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3181\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  41.6s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 4.3936 - val_loss: 13.3699\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.2098 - val_loss: 10.8972\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.4360 - val_loss: 7.7330\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0926 - val_loss: 5.0744\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9168 - val_loss: 3.2363\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8186 - val_loss: 2.1597\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7619 - val_loss: 1.4840\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7266 - val_loss: 1.1083\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7031 - val_loss: 0.8942\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6858 - val_loss: 0.7687\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6720 - val_loss: 0.6947\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6602 - val_loss: 0.6524\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6498 - val_loss: 0.6234\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6401 - val_loss: 0.6061\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6312 - val_loss: 0.5933\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6227 - val_loss: 0.5819\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6147 - val_loss: 0.5733\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6070 - val_loss: 0.5650\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5997 - val_loss: 0.5578\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5926 - val_loss: 0.5508\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5859 - val_loss: 0.5446\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5794 - val_loss: 0.5384\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5732 - val_loss: 0.5326\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5671 - val_loss: 0.5266\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5614 - val_loss: 0.5214\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5558 - val_loss: 0.5166\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5504 - val_loss: 0.5116\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5453 - val_loss: 0.5076\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5403 - val_loss: 0.5035\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5356 - val_loss: 0.4989\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5309 - val_loss: 0.4946\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5265 - val_loss: 0.4915\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5222 - val_loss: 0.4883\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5181 - val_loss: 0.4856\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5141 - val_loss: 0.4828\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5103 - val_loss: 0.4789\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5066 - val_loss: 0.4780\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5030 - val_loss: 0.4742\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4995 - val_loss: 0.4729\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4962 - val_loss: 0.4714\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4929 - val_loss: 0.4686\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4897 - val_loss: 0.4666\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4867 - val_loss: 0.4646\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4837 - val_loss: 0.4636\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4809 - val_loss: 0.4616\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4781 - val_loss: 0.4582\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4755 - val_loss: 0.4581\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4729 - val_loss: 0.4573\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4704 - val_loss: 0.4560\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4680 - val_loss: 0.4544\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4656 - val_loss: 0.4525\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4633 - val_loss: 0.4527\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4611 - val_loss: 0.4522\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4589 - val_loss: 0.4509\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4568 - val_loss: 0.4509\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4548 - val_loss: 0.4513\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4529 - val_loss: 0.4496\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4510 - val_loss: 0.4510\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4491 - val_loss: 0.4502\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4473 - val_loss: 0.4478\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4456 - val_loss: 0.4485\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4440 - val_loss: 0.4488\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4423 - val_loss: 0.4477\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4408 - val_loss: 0.4497\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4392 - val_loss: 0.4512\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4378 - val_loss: 0.4484\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4363 - val_loss: 0.4483\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4349 - val_loss: 0.4494\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4336 - val_loss: 0.4492\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4322 - val_loss: 0.4476\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4309 - val_loss: 0.4481\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4296 - val_loss: 0.4503\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4284 - val_loss: 0.4486\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4272 - val_loss: 0.4491\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.4496\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4249 - val_loss: 0.4483\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4238 - val_loss: 0.4474\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4227 - val_loss: 0.4490\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4217 - val_loss: 0.4495\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.4468\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4196 - val_loss: 0.4492\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4186 - val_loss: 0.4525\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4177 - val_loss: 0.4504\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4167 - val_loss: 0.4525\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4158 - val_loss: 0.4495\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4148 - val_loss: 0.4548\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4140 - val_loss: 0.4512\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4132 - val_loss: 0.4481\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4123 - val_loss: 0.4472\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4114 - val_loss: 0.4506\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4209\n",
            "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  52.1s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 3.4569 - val_loss: 7.5238\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.5656 - val_loss: 8.6120\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0607 - val_loss: 8.4896\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8953 - val_loss: 7.7423\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8236 - val_loss: 6.8202\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7840 - val_loss: 5.9344\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7579 - val_loss: 5.1492\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7381 - val_loss: 4.4548\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7216 - val_loss: 3.9122\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7071 - val_loss: 3.4233\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6937 - val_loss: 2.9997\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6814 - val_loss: 2.6082\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6701 - val_loss: 2.2766\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6593 - val_loss: 1.9984\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6491 - val_loss: 1.7447\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6395 - val_loss: 1.5300\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6303 - val_loss: 1.3410\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6217 - val_loss: 1.1762\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6133 - val_loss: 1.0345\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6055 - val_loss: 0.9174\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5980 - val_loss: 0.8153\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5908 - val_loss: 0.7363\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5839 - val_loss: 0.6696\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5774 - val_loss: 0.6187\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5711 - val_loss: 0.5778\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5652 - val_loss: 0.5491\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5594 - val_loss: 0.5299\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5540 - val_loss: 0.5199\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5486 - val_loss: 0.5172\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5438 - val_loss: 0.5206\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5389 - val_loss: 0.5312\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5343 - val_loss: 0.5447\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5298 - val_loss: 0.5639\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5256 - val_loss: 0.5821\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5216 - val_loss: 0.6039\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5177 - val_loss: 0.6306\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5140 - val_loss: 0.6564\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5104 - val_loss: 0.6820\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5069 - val_loss: 0.7087\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.5160\n",
            "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  23.8s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 4.0974 - val_loss: 7.4460\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.1844 - val_loss: 5.2071\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.4253 - val_loss: 2.9554\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0762 - val_loss: 1.7752\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9094 - val_loss: 1.1201\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8243 - val_loss: 0.8519\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7768 - val_loss: 0.7512\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7473 - val_loss: 0.7064\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7264 - val_loss: 0.6896\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7098 - val_loss: 0.6760\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6955 - val_loss: 0.6687\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6830 - val_loss: 0.6577\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6713 - val_loss: 0.6454\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6604 - val_loss: 0.6355\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6503 - val_loss: 0.6256\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6407 - val_loss: 0.6213\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6317 - val_loss: 0.6120\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6230 - val_loss: 0.6024\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6148 - val_loss: 0.5998\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6072 - val_loss: 0.5901\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5996 - val_loss: 0.5822\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5925 - val_loss: 0.5763\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5857 - val_loss: 0.5664\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5791 - val_loss: 0.5574\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5728 - val_loss: 0.5527\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5668 - val_loss: 0.5452\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5610 - val_loss: 0.5437\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5555 - val_loss: 0.5366\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5501 - val_loss: 0.5322\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5450 - val_loss: 0.5264\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5399 - val_loss: 0.5234\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5352 - val_loss: 0.5175\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5305 - val_loss: 0.5137\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5262 - val_loss: 0.5078\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5219 - val_loss: 0.5045\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5178 - val_loss: 0.4970\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5139 - val_loss: 0.4911\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5101 - val_loss: 0.4887\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5064 - val_loss: 0.4847\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5029 - val_loss: 0.4815\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4994 - val_loss: 0.4776\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4962 - val_loss: 0.4736\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.4706\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4901 - val_loss: 0.4673\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4871 - val_loss: 0.4655\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4843 - val_loss: 0.4625\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4816 - val_loss: 0.4576\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4789 - val_loss: 0.4554\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4764 - val_loss: 0.4525\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4740 - val_loss: 0.4495\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4716 - val_loss: 0.4468\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4693 - val_loss: 0.4446\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4670 - val_loss: 0.4420\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4649 - val_loss: 0.4394\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4628 - val_loss: 0.4373\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4607 - val_loss: 0.4349\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4588 - val_loss: 0.4330\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4569 - val_loss: 0.4311\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4550 - val_loss: 0.4291\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4532 - val_loss: 0.4277\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4515 - val_loss: 0.4257\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4498 - val_loss: 0.4241\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4482 - val_loss: 0.4224\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4466 - val_loss: 0.4208\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4451 - val_loss: 0.4193\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4436 - val_loss: 0.4180\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4422 - val_loss: 0.4164\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4408 - val_loss: 0.4151\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4395 - val_loss: 0.4141\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4382 - val_loss: 0.4124\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4369 - val_loss: 0.4112\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4357 - val_loss: 0.4101\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4345 - val_loss: 0.4088\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4334 - val_loss: 0.4081\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4323 - val_loss: 0.4073\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4312 - val_loss: 0.4070\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4301 - val_loss: 0.4056\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4291 - val_loss: 0.4040\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4281 - val_loss: 0.4034\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4271 - val_loss: 0.4033\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4262 - val_loss: 0.4019\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4253 - val_loss: 0.4008\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4244 - val_loss: 0.4002\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4236 - val_loss: 0.3996\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4227 - val_loss: 0.3983\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4219 - val_loss: 0.3980\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4211 - val_loss: 0.3981\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4203 - val_loss: 0.3969\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4195 - val_loss: 0.3978\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4188 - val_loss: 0.3961\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4180 - val_loss: 0.3951\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4173 - val_loss: 0.3938\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4166 - val_loss: 0.3938\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4159 - val_loss: 0.3935\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4152 - val_loss: 0.3934\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4146 - val_loss: 0.3932\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4139 - val_loss: 0.3939\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4132 - val_loss: 0.3913\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4127 - val_loss: 0.3916\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4121 - val_loss: 0.3918\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4139\n",
            "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  59.4s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.0765 - val_loss: 1.3536\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7485 - val_loss: 0.7463\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6415 - val_loss: 0.5899\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5900 - val_loss: 0.5366\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5507 - val_loss: 0.5063\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5188 - val_loss: 0.4813\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4926 - val_loss: 0.4639\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4721 - val_loss: 0.4427\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4552 - val_loss: 0.4393\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4420 - val_loss: 0.4137\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4313 - val_loss: 0.4071\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4224 - val_loss: 0.3983\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4147 - val_loss: 0.3933\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4089 - val_loss: 0.3972\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.3852\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3986 - val_loss: 0.3830\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3939 - val_loss: 0.3947\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3900 - val_loss: 0.3713\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3857 - val_loss: 0.3752\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3828 - val_loss: 0.3741\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3803 - val_loss: 0.3782\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3766 - val_loss: 0.3637\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3723\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3721 - val_loss: 0.3707\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.4047\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3679 - val_loss: 0.3839\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3654 - val_loss: 0.4167\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3637 - val_loss: 0.3500\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3607 - val_loss: 0.3792\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 0.3636\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3576 - val_loss: 0.3476\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3566 - val_loss: 0.3566\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.3611\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3541 - val_loss: 0.3414\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3527 - val_loss: 0.3474\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3508 - val_loss: 0.3944\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3507 - val_loss: 0.4403\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3502 - val_loss: 0.4722\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.3722\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3481 - val_loss: 0.4019\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3467 - val_loss: 0.3376\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3449 - val_loss: 0.3377\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3450 - val_loss: 0.3354\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3433 - val_loss: 0.3737\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3441 - val_loss: 0.3336\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.3562\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3415 - val_loss: 0.3547\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3410 - val_loss: 0.3399\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3400 - val_loss: 0.3304\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3395 - val_loss: 0.3849\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3393 - val_loss: 0.3430\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3382 - val_loss: 0.3363\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3378 - val_loss: 0.3387\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3373 - val_loss: 0.3294\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3361 - val_loss: 0.3655\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3369 - val_loss: 0.3310\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3354 - val_loss: 0.3729\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3347 - val_loss: 0.3374\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3340 - val_loss: 0.3263\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3331 - val_loss: 0.3402\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3329 - val_loss: 0.3440\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3321 - val_loss: 0.3581\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3320 - val_loss: 0.3303\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3311 - val_loss: 0.3680\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3311 - val_loss: 0.3292\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3311 - val_loss: 0.3276\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3299 - val_loss: 0.3563\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3294 - val_loss: 0.3296\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3282 - val_loss: 0.3440\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3551\n",
            "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time= 1.4min\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.8880 - val_loss: 3.4090\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7244 - val_loss: 1.6754\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6372 - val_loss: 0.9319\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5910 - val_loss: 0.6042\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5529 - val_loss: 0.5061\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5225 - val_loss: 0.5058\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4977 - val_loss: 0.5272\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4770 - val_loss: 0.5600\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4600 - val_loss: 0.5367\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4469 - val_loss: 0.5221\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4356 - val_loss: 0.4878\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4264 - val_loss: 0.4531\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4187 - val_loss: 0.4182\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4124 - val_loss: 0.3877\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4064 - val_loss: 0.3818\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4022\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3962 - val_loss: 0.4348\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3926 - val_loss: 0.4935\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3878 - val_loss: 0.5340\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3847 - val_loss: 0.5982\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3819 - val_loss: 0.6541\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3786 - val_loss: 0.7245\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3758 - val_loss: 0.8045\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3735 - val_loss: 0.8587\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3711 - val_loss: 0.9089\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3884\n",
            "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  18.3s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 2.1014 - val_loss: 2.1643\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7146 - val_loss: 0.6141\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6063 - val_loss: 0.5601\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5633 - val_loss: 0.5241\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5302 - val_loss: 0.5017\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5034 - val_loss: 0.4749\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4814 - val_loss: 0.4558\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4633 - val_loss: 0.4297\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4483 - val_loss: 0.4464\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4374 - val_loss: 0.4189\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4266 - val_loss: 0.4438\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4188 - val_loss: 0.4250\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4121 - val_loss: 0.4009\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4067 - val_loss: 0.4403\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4025 - val_loss: 0.4014\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3981 - val_loss: 0.4247\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.3964\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3914 - val_loss: 0.3974\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3887 - val_loss: 0.4229\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3860 - val_loss: 0.4053\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3840 - val_loss: 0.3989\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3815 - val_loss: 0.3957\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3793 - val_loss: 0.3864\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3774 - val_loss: 0.4022\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3756 - val_loss: 0.3729\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3733 - val_loss: 0.3645\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3716 - val_loss: 0.4107\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3702 - val_loss: 0.3925\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3688 - val_loss: 0.4265\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.3879\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3659 - val_loss: 0.3789\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3643 - val_loss: 0.4080\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3631 - val_loss: 0.3873\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.4232\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.3718\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3593 - val_loss: 0.3663\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3555\n",
            "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  41.7s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.2908 - val_loss: 297.3654\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.1716 - val_loss: 539.0368\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 6.2333 - val_loss: 3736.4534\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 11.9933 - val_loss: 12227.7012\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 54.7041 - val_loss: 61529.1094\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2281.0830 - val_loss: 268363.6562\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2760.9963 - val_loss: 1210518.3750\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 40359.4219 - val_loss: 5411009.5000\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 83692.0781 - val_loss: 24506734.0000\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1055627.6250 - val_loss: 119813208.0000\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1860451.2500 - val_loss: 529731904.0000\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 1402368.0000\n",
            "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=  10.9s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0446 - val_loss: 15.8284\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5210 - val_loss: 22.4892\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5063 - val_loss: 24.7894\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5101 - val_loss: 22.4864\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5097 - val_loss: 21.9009\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5089 - val_loss: 21.2895\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5113 - val_loss: 19.9064\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5102 - val_loss: 22.5013\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5069 - val_loss: 20.0987\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5087 - val_loss: 10.7128\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5083 - val_loss: 19.7319\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5049 - val_loss: 24.3237\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5077 - val_loss: 25.9485\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5199 - val_loss: 10.5277\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5078 - val_loss: 17.1916\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5064 - val_loss: 21.8346\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5058 - val_loss: 11.7743\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5101 - val_loss: 14.1555\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5071 - val_loss: 20.9814\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5032 - val_loss: 12.3621\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5071 - val_loss: 25.9146\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5132 - val_loss: 16.0461\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5071 - val_loss: 19.4877\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5084 - val_loss: 12.1054\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.7813\n",
            "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=  13.7s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.2328 - val_loss: 307.7496\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9214 - val_loss: 76.3015\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3774 - val_loss: 795.2289\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 34.9847 - val_loss: 704.0445\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3027 - val_loss: 2668.0278\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 9.2431 - val_loss: 1446.2599\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.8034 - val_loss: 1540.5371\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 41.9015 - val_loss: 1396.7107\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 10.9509 - val_loss: 1334.0837\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.4803 - val_loss: 216.7265\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 13.8365 - val_loss: 125.2063\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6450 - val_loss: 2.2902\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7449 - val_loss: 790.5421\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 9.2398 - val_loss: 468.7424\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.2300 - val_loss: 1073.9153\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 37.3801 - val_loss: 865.6381\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 8.9708 - val_loss: 1128.1497\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.8291 - val_loss: 499.5189\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 24.8681 - val_loss: 309.7940\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.6469 - val_loss: 354.6340\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.2841 - val_loss: 559.4486\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.5495 - val_loss: 393.8696\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.6226\n",
            "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=  12.8s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.2632 - val_loss: 1.4543\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6364 - val_loss: 0.9557\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5396 - val_loss: 0.4628\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4783 - val_loss: 0.4214\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4400 - val_loss: 0.3984\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4169 - val_loss: 0.4056\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.3741\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3888 - val_loss: 0.3926\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3809 - val_loss: 0.3832\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3743 - val_loss: 0.3929\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3697 - val_loss: 0.3570\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3640 - val_loss: 0.3790\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3595 - val_loss: 0.3840\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3569 - val_loss: 0.3950\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3530 - val_loss: 0.3751\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3503 - val_loss: 0.3955\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3476 - val_loss: 0.3900\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.3905\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3420 - val_loss: 0.3944\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3404 - val_loss: 0.3811\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3378 - val_loss: 0.3906\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3624\n",
            "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  15.5s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0130 - val_loss: 0.5822\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5558 - val_loss: 0.4873\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4781 - val_loss: 0.4420\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4376 - val_loss: 0.4139\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4111 - val_loss: 0.4132\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3947 - val_loss: 0.4464\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3840 - val_loss: 0.4717\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3760 - val_loss: 0.5331\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3682 - val_loss: 0.6951\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3633 - val_loss: 0.6944\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3574 - val_loss: 0.8506\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.7660\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3509 - val_loss: 0.8731\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3487 - val_loss: 0.9306\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3463 - val_loss: 0.9345\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3685\n",
            "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  11.0s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1090 - val_loss: 0.6796\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5639 - val_loss: 0.4957\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4920 - val_loss: 0.4633\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4547 - val_loss: 0.4565\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4305 - val_loss: 0.4150\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4141 - val_loss: 0.4331\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4026 - val_loss: 0.3887\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3936 - val_loss: 0.3785\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3857 - val_loss: 0.4233\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3819 - val_loss: 0.3652\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3760 - val_loss: 0.4336\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3725 - val_loss: 0.3763\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3683 - val_loss: 0.3632\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.4460\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3624 - val_loss: 0.3555\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3584 - val_loss: 0.3942\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3560 - val_loss: 0.3623\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3525 - val_loss: 0.3775\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3505 - val_loss: 0.3816\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3480 - val_loss: 0.3414\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3463 - val_loss: 0.3460\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3446 - val_loss: 0.3273\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3424 - val_loss: 0.3277\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3395 - val_loss: 0.4355\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3401 - val_loss: 0.3435\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3366 - val_loss: 0.3227\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3342 - val_loss: 0.4432\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3358 - val_loss: 0.3328\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3332 - val_loss: 0.3987\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3323 - val_loss: 0.3426\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3293 - val_loss: 0.3344\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3279 - val_loss: 0.3615\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3270 - val_loss: 0.3466\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3243 - val_loss: 0.3603\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3245 - val_loss: 0.3136\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3223 - val_loss: 0.3636\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3221 - val_loss: 0.3375\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3212 - val_loss: 0.5186\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3229 - val_loss: 0.3307\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3195 - val_loss: 0.4023\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3181 - val_loss: 0.3346\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3165 - val_loss: 0.3601\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3162 - val_loss: 0.3263\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3146 - val_loss: 0.3641\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3152 - val_loss: 0.3073\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3128 - val_loss: 0.3734\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3118 - val_loss: 0.3148\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3118 - val_loss: 0.3000\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3095 - val_loss: 0.4186\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3113 - val_loss: 0.2988\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3086 - val_loss: 0.4245\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3091 - val_loss: 0.3056\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3077 - val_loss: 0.3068\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3071 - val_loss: 0.3015\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3059 - val_loss: 0.2945\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3037 - val_loss: 0.3219\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3051 - val_loss: 0.3270\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3059 - val_loss: 0.3292\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3044 - val_loss: 0.3899\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3060 - val_loss: 0.3813\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3040 - val_loss: 0.3135\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3014 - val_loss: 0.3082\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3013 - val_loss: 0.2969\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3008 - val_loss: 0.2998\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3010 - val_loss: 0.2940\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2992 - val_loss: 0.3335\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2991 - val_loss: 0.3008\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2982 - val_loss: 0.3329\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2976 - val_loss: 0.2917\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2959 - val_loss: 0.3223\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2967 - val_loss: 0.2883\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2963 - val_loss: 0.2927\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2956 - val_loss: 0.2998\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2947 - val_loss: 0.2869\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2948 - val_loss: 0.3133\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2929 - val_loss: 0.3490\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2960 - val_loss: 0.2858\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2934 - val_loss: 0.3066\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2934 - val_loss: 0.2879\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2918 - val_loss: 0.2866\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2914 - val_loss: 0.3093\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2917 - val_loss: 0.2987\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2912 - val_loss: 0.2895\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2906 - val_loss: 0.3320\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2903 - val_loss: 0.2987\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2902 - val_loss: 0.3022\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2896 - val_loss: 0.3395\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3028\n",
            "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time= 1.0min\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.1150 - val_loss: 29.5063\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0854 - val_loss: 33.7784\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9418 - val_loss: 4.0125\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6369 - val_loss: 0.5556\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5632 - val_loss: 0.5119\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5371 - val_loss: 0.4888\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5149 - val_loss: 0.4729\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4964 - val_loss: 0.4559\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4803 - val_loss: 0.4601\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4670 - val_loss: 0.4303\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4561 - val_loss: 0.4205\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4469 - val_loss: 0.4242\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4391 - val_loss: 0.4107\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4325 - val_loss: 0.4231\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4270 - val_loss: 0.4221\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4221 - val_loss: 0.4084\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4179 - val_loss: 0.4209\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4143 - val_loss: 0.4017\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4106 - val_loss: 0.4322\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4001\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.4263\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4027 - val_loss: 0.4032\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.4039\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3981 - val_loss: 0.3764\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3962 - val_loss: 0.4241\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3944 - val_loss: 0.3779\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3925 - val_loss: 0.4126\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3910 - val_loss: 0.3967\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3889 - val_loss: 0.4045\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3880 - val_loss: 0.3748\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3864 - val_loss: 0.3717\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3851 - val_loss: 0.3676\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.4054\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3825 - val_loss: 0.3924\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3815 - val_loss: 0.3611\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3800 - val_loss: 0.4182\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3792 - val_loss: 0.3539\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3779 - val_loss: 0.4403\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3769 - val_loss: 0.3551\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3757 - val_loss: 0.4125\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3748 - val_loss: 0.3665\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3735 - val_loss: 0.3591\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.3570\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3717 - val_loss: 0.4125\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3714 - val_loss: 0.3547\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.3779\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3692 - val_loss: 0.3886\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3877\n",
            "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  41.7s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.8463 - val_loss: 0.7805\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7088 - val_loss: 1.1550\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6196 - val_loss: 1.8115\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5692 - val_loss: 2.6113\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5319 - val_loss: 3.2626\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5046 - val_loss: 3.5247\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4841 - val_loss: 3.5926\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4679 - val_loss: 3.5562\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4551 - val_loss: 2.9541\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4459 - val_loss: 2.5606\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4377 - val_loss: 2.1560\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4866\n",
            "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=   8.7s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.7445 - val_loss: 2.5834\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7268 - val_loss: 3.5564\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6419 - val_loss: 1.7895\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6134 - val_loss: 1.7436\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5564 - val_loss: 0.6344\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5303 - val_loss: 0.8713\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5070 - val_loss: 0.5604\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4919 - val_loss: 0.4695\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4759 - val_loss: 0.4942\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4659 - val_loss: 0.4375\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4561 - val_loss: 0.4536\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4481 - val_loss: 0.4276\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4408 - val_loss: 0.4084\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4354 - val_loss: 0.4897\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4300 - val_loss: 0.4018\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4246 - val_loss: 0.5505\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4211 - val_loss: 0.4602\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4171 - val_loss: 0.4347\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4132 - val_loss: 0.3835\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4092 - val_loss: 0.4115\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.3817\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4035 - val_loss: 0.3737\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4008 - val_loss: 0.3720\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3983 - val_loss: 0.4318\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3970 - val_loss: 0.4158\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3943 - val_loss: 0.3821\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3922 - val_loss: 0.4069\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3909 - val_loss: 0.4024\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3887 - val_loss: 0.5904\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3898 - val_loss: 0.4027\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3858 - val_loss: 0.4216\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3847 - val_loss: 0.3603\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3825 - val_loss: 0.4134\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3819 - val_loss: 0.3633\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3805 - val_loss: 0.3542\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3786 - val_loss: 0.3568\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3783 - val_loss: 0.4216\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3770 - val_loss: 0.5522\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3792 - val_loss: 0.5648\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3763 - val_loss: 0.6416\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3785 - val_loss: 0.3847\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3729 - val_loss: 0.5255\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3744 - val_loss: 0.7023\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.7508\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3771 - val_loss: 0.5608\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3745\n",
            "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  41.8s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.0682 - val_loss: 6.4183\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7154 - val_loss: 16.7917\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5830 - val_loss: 4.7823\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4475 - val_loss: 8.6076\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4779 - val_loss: 1.8025\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4007 - val_loss: 0.3654\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3682 - val_loss: 0.3786\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3590 - val_loss: 0.4054\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3533 - val_loss: 0.3911\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.3905\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3445 - val_loss: 0.3546\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3394 - val_loss: 0.3611\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3351 - val_loss: 0.3659\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3334 - val_loss: 0.3634\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3293 - val_loss: 0.3575\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3272 - val_loss: 0.3561\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3240 - val_loss: 0.3602\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3224 - val_loss: 0.3474\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3186 - val_loss: 0.3502\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3163 - val_loss: 0.3389\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3366\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3120 - val_loss: 0.3764\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3100 - val_loss: 0.3169\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3088 - val_loss: 0.3105\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3044 - val_loss: 0.3597\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3034 - val_loss: 0.3121\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3029 - val_loss: 0.3274\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3017 - val_loss: 0.3509\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2985 - val_loss: 0.3330\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2962 - val_loss: 0.2958\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2951 - val_loss: 0.3132\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2934 - val_loss: 0.2887\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2909 - val_loss: 0.3223\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2889 - val_loss: 0.3223\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2880 - val_loss: 0.3016\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2869 - val_loss: 0.3732\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2857 - val_loss: 0.3113\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2847 - val_loss: 0.3495\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2835 - val_loss: 0.2954\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2820 - val_loss: 0.3323\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2807 - val_loss: 0.2872\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2796 - val_loss: 0.2925\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2787 - val_loss: 0.2850\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2767 - val_loss: 0.3183\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2768 - val_loss: 0.3116\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2756 - val_loss: 0.3266\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2738 - val_loss: 0.2953\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2736 - val_loss: 0.2868\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2712 - val_loss: 0.2781\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2711 - val_loss: 0.3304\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2697 - val_loss: 0.3192\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2686 - val_loss: 0.3164\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2683 - val_loss: 0.2780\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2666 - val_loss: 0.2881\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2652 - val_loss: 0.2911\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2657 - val_loss: 0.2800\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2636 - val_loss: 0.3161\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2643 - val_loss: 0.2755\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2632 - val_loss: 0.2882\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2610 - val_loss: 0.2781\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2620 - val_loss: 0.3403\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2609 - val_loss: 0.2814\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2600 - val_loss: 0.3300\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2598 - val_loss: 0.2781\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2574 - val_loss: 0.2968\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2585 - val_loss: 0.3599\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2597 - val_loss: 0.4967\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2593 - val_loss: 0.2916\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3051\n",
            "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time= 1.4min\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.8717 - val_loss: 0.7369\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 0.4431\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4272 - val_loss: 0.3919\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3961 - val_loss: 0.3834\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3777 - val_loss: 0.3951\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3661 - val_loss: 0.4650\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3580 - val_loss: 0.6408\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3524 - val_loss: 0.7273\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3462 - val_loss: 0.9104\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3421 - val_loss: 0.6969\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3364 - val_loss: 0.6999\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3327 - val_loss: 0.7835\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3292 - val_loss: 0.8539\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3277 - val_loss: 0.8282\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3525\n",
            "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  11.4s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 2s 4ms/step - loss: 0.9177 - val_loss: 0.9196\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4767 - val_loss: 2.1025\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4329 - val_loss: 3.5511\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4408 - val_loss: 1.5867\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3910 - val_loss: 0.4227\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3715 - val_loss: 0.3738\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3634 - val_loss: 0.3350\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3569 - val_loss: 0.3384\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3518 - val_loss: 0.3720\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3514 - val_loss: 0.3276\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3456 - val_loss: 0.3969\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3420 - val_loss: 0.3330\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3373 - val_loss: 0.3226\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3347 - val_loss: 0.3670\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3323 - val_loss: 0.3203\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3294 - val_loss: 0.3560\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3269 - val_loss: 0.3218\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3238 - val_loss: 0.3563\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3223 - val_loss: 0.3354\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3194 - val_loss: 0.3605\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3179 - val_loss: 0.3141\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3157 - val_loss: 0.3232\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3132 - val_loss: 0.3610\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3123 - val_loss: 0.3065\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3108 - val_loss: 0.3355\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3076 - val_loss: 0.3266\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3058 - val_loss: 0.3078\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3044 - val_loss: 0.3198\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3050 - val_loss: 0.4784\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3045 - val_loss: 0.3009\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2997 - val_loss: 0.3500\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2986 - val_loss: 0.2898\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2984 - val_loss: 0.3720\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2969 - val_loss: 0.2971\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2933 - val_loss: 0.2964\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2910 - val_loss: 0.3695\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2904 - val_loss: 0.3549\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2927 - val_loss: 0.4049\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2915 - val_loss: 0.3326\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2908 - val_loss: 0.5216\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2906 - val_loss: 0.3043\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2868 - val_loss: 0.3285\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3012\n",
            "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  34.7s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.9615 - val_loss: 10.9251\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5921 - val_loss: 3.3912\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4539 - val_loss: 0.4039\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3914 - val_loss: 0.3692\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3713 - val_loss: 0.3555\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3601 - val_loss: 0.3875\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3523 - val_loss: 0.3633\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3454 - val_loss: 0.3991\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3411 - val_loss: 0.3797\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3382 - val_loss: 0.3703\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3351 - val_loss: 0.3312\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3304 - val_loss: 0.3509\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3269 - val_loss: 0.3786\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3261 - val_loss: 0.3304\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3217 - val_loss: 0.3506\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3195 - val_loss: 0.3492\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3172 - val_loss: 0.3253\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3157 - val_loss: 0.3441\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3124 - val_loss: 0.3338\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3108 - val_loss: 0.3214\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3086 - val_loss: 0.3800\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3084 - val_loss: 0.3090\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3050 - val_loss: 0.3790\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3068 - val_loss: 0.3685\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3030 - val_loss: 0.3252\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2988 - val_loss: 0.3069\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2978 - val_loss: 0.3308\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2970 - val_loss: 0.3484\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2941 - val_loss: 0.3664\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2931 - val_loss: 0.3322\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2933 - val_loss: 0.3097\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2902 - val_loss: 0.2894\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2874 - val_loss: 0.3229\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2856 - val_loss: 0.3018\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2842 - val_loss: 0.2934\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2831 - val_loss: 0.3529\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2833 - val_loss: 0.4180\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2869 - val_loss: 0.3531\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2826 - val_loss: 0.3071\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2808 - val_loss: 0.3268\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2792 - val_loss: 0.3048\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2774 - val_loss: 0.3034\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3158\n",
            "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  33.3s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8381 - val_loss: 0.6551\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4570 - val_loss: 0.4129\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4107 - val_loss: 0.6097\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3911 - val_loss: 0.6574\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3755 - val_loss: 0.6379\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3647 - val_loss: 0.8601\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3603 - val_loss: 1.0634\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3515 - val_loss: 1.1252\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3456 - val_loss: 1.2303\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3424 - val_loss: 0.7979\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3374 - val_loss: 0.8341\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.7676\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3596\n",
            "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  10.3s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.8683 - val_loss: 2.2007\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5072 - val_loss: 3.3028\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4486 - val_loss: 0.9130\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.5328\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3842 - val_loss: 0.3609\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3729 - val_loss: 0.4151\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3659 - val_loss: 0.3580\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3596 - val_loss: 0.3516\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3528 - val_loss: 0.3983\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3511 - val_loss: 0.3323\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.4231\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3419 - val_loss: 0.3283\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3374 - val_loss: 0.3466\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3337 - val_loss: 0.4040\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3325 - val_loss: 0.3272\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3291 - val_loss: 0.3768\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3263 - val_loss: 0.3209\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3227 - val_loss: 0.3296\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3216 - val_loss: 0.3740\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3190 - val_loss: 0.3369\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3182 - val_loss: 0.3761\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3183 - val_loss: 0.3095\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3148 - val_loss: 0.3425\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3133 - val_loss: 0.3229\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3101 - val_loss: 0.3092\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3075 - val_loss: 0.3115\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3047 - val_loss: 0.3946\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3062 - val_loss: 0.3293\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3045 - val_loss: 0.4156\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3032 - val_loss: 0.3340\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3001 - val_loss: 0.2992\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2976 - val_loss: 0.4786\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3003 - val_loss: 0.2956\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2945 - val_loss: 0.4379\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2955 - val_loss: 0.3091\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2917 - val_loss: 0.4437\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2919 - val_loss: 0.3648\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2939 - val_loss: 0.5943\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2935 - val_loss: 0.3076\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2892 - val_loss: 0.3334\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2865 - val_loss: 0.3316\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2854 - val_loss: 0.3438\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2851 - val_loss: 0.2857\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2822 - val_loss: 0.3290\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2828 - val_loss: 0.3100\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2802 - val_loss: 0.3267\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2801 - val_loss: 0.2843\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2793 - val_loss: 0.2977\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2783 - val_loss: 0.4493\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2781 - val_loss: 0.2911\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2754 - val_loss: 0.4364\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2755 - val_loss: 0.3454\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2762 - val_loss: 0.3108\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2751 - val_loss: 0.3290\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2734 - val_loss: 0.2909\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2721 - val_loss: 0.3855\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2718 - val_loss: 0.2864\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.2915\n",
            "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  43.6s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.2259 - val_loss: 0.5753\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5658 - val_loss: 8.9879\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5484 - val_loss: 11.0986\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5602 - val_loss: 1.1306\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4336 - val_loss: 0.5258\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4499\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3939 - val_loss: 0.4056\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3835 - val_loss: 0.3998\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3766 - val_loss: 0.3957\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3712 - val_loss: 0.3903\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3672 - val_loss: 0.3688\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.3651\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3587 - val_loss: 0.3709\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.3817\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.3623\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3528 - val_loss: 0.3671\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3490 - val_loss: 0.3671\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.3606\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.3552\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.3535\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3416 - val_loss: 0.3520\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3388 - val_loss: 0.3475\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3372 - val_loss: 0.3511\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3374 - val_loss: 0.3303\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3333 - val_loss: 0.3687\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3334 - val_loss: 0.3247\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3336 - val_loss: 0.3387\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.3365\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3279 - val_loss: 0.3381\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3276 - val_loss: 0.3208\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3255 - val_loss: 0.3219\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3256 - val_loss: 0.3150\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3238 - val_loss: 0.3452\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3221 - val_loss: 0.3161\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3209 - val_loss: 0.3141\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3190 - val_loss: 0.3868\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3189 - val_loss: 0.3679\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3189 - val_loss: 0.3518\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3160 - val_loss: 0.3144\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3154 - val_loss: 0.3435\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3190 - val_loss: 0.3184\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3150 - val_loss: 0.3184\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3148 - val_loss: 0.3141\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3112 - val_loss: 0.3436\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3143 - val_loss: 0.3060\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3102 - val_loss: 0.3315\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3089 - val_loss: 0.3343\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3122 - val_loss: 0.3240\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3074 - val_loss: 0.3020\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3068 - val_loss: 0.3566\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3058 - val_loss: 0.3296\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3048 - val_loss: 0.3137\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3048 - val_loss: 0.3176\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3035 - val_loss: 0.3059\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3036 - val_loss: 0.3623\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3044 - val_loss: 0.2996\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3015 - val_loss: 0.3735\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3037 - val_loss: 0.3270\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3002 - val_loss: 0.3069\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2990 - val_loss: 0.3264\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2998 - val_loss: 0.3635\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2986 - val_loss: 0.3472\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.2983 - val_loss: 0.3384\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2965 - val_loss: 0.3588\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2957 - val_loss: 0.3099\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3033 - val_loss: 0.3029\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3339\n",
            "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time= 1.4min\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.1975 - val_loss: 0.8898\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5319 - val_loss: 0.5270\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4524 - val_loss: 0.4844\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4199 - val_loss: 0.4250\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.3735\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3907 - val_loss: 0.3859\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3833 - val_loss: 0.4576\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3754 - val_loss: 0.4926\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.6246\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3660 - val_loss: 0.5262\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3611 - val_loss: 0.5952\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.6355\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3550 - val_loss: 0.7437\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3530 - val_loss: 0.7102\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3502 - val_loss: 0.6823\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3613\n",
            "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  11.8s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.1315 - val_loss: 2.8528\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6016 - val_loss: 2.3412\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5108 - val_loss: 0.9015\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4594 - val_loss: 0.8313\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4291 - val_loss: 0.5217\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4956\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.3745\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3917 - val_loss: 0.4012\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3848 - val_loss: 0.4169\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3815 - val_loss: 0.3843\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3756 - val_loss: 0.6122\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3743 - val_loss: 0.3579\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3671 - val_loss: 0.3497\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3632 - val_loss: 0.5161\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3635 - val_loss: 0.4273\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3592 - val_loss: 0.5739\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3601 - val_loss: 0.4975\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3547 - val_loss: 0.4886\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.3371\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.4118\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3485 - val_loss: 0.3311\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3460 - val_loss: 0.3289\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3435 - val_loss: 0.3287\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3410 - val_loss: 0.5230\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3438 - val_loss: 0.7683\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3423 - val_loss: 0.8921\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3449 - val_loss: 0.4875\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3369 - val_loss: 0.6193\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3374 - val_loss: 0.3481\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3328 - val_loss: 0.5801\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3329 - val_loss: 0.3675\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3309 - val_loss: 1.0207\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3404 - val_loss: 0.6377\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3366\n",
            "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  26.7s\n",
            "Epoch 1/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.8194 - val_loss: 1.8036\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4857 - val_loss: 2.0827\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4266 - val_loss: 0.3796\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3857 - val_loss: 0.4283\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3740 - val_loss: 0.3617\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3620 - val_loss: 0.4566\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3566 - val_loss: 0.3573\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3492 - val_loss: 0.3380\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3432 - val_loss: 0.3757\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3389 - val_loss: 0.4069\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3380 - val_loss: 0.5455\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3368 - val_loss: 0.6470\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3319 - val_loss: 0.3109\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3257 - val_loss: 0.3198\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3240 - val_loss: 0.3065\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3204 - val_loss: 0.3252\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3175 - val_loss: 0.3961\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3154 - val_loss: 0.2998\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3139 - val_loss: 0.3075\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3113 - val_loss: 0.4588\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3114 - val_loss: 0.3290\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3078 - val_loss: 0.5069\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3067 - val_loss: 0.5464\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3050 - val_loss: 0.5905\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3037 - val_loss: 0.2991\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2998 - val_loss: 0.5100\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3000 - val_loss: 0.4396\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3001 - val_loss: 0.4055\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2961 - val_loss: 0.2979\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2947 - val_loss: 0.3499\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2944 - val_loss: 0.3154\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2906 - val_loss: 0.3683\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2897 - val_loss: 0.2825\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2876 - val_loss: 0.3072\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2861 - val_loss: 0.3648\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2862 - val_loss: 0.3245\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2841 - val_loss: 0.4705\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2816 - val_loss: 0.2799\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2821 - val_loss: 0.3705\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2803 - val_loss: 0.2795\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2800 - val_loss: 0.4555\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2808 - val_loss: 0.2733\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2751 - val_loss: 0.3850\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2752 - val_loss: 0.3173\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2732 - val_loss: 0.2790\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2734 - val_loss: 0.3133\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2732 - val_loss: 0.3046\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2715 - val_loss: 0.3119\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2709 - val_loss: 0.2979\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2688 - val_loss: 0.3078\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2681 - val_loss: 0.2704\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2669 - val_loss: 0.2914\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2666 - val_loss: 0.5759\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2684 - val_loss: 0.4312\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2681 - val_loss: 0.7045\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2681 - val_loss: 0.4374\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2660 - val_loss: 0.4762\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2637 - val_loss: 0.2840\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2635 - val_loss: 0.5647\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2651 - val_loss: 0.4714\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2636 - val_loss: 0.3337\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3,\n",
              "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7fc5155c8850>,\n",
              "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
              "                                                          0.02390836445593178,\n",
              "                                                          0.008731907739399206,\n",
              "                                                          0.004725396149933917,\n",
              "                                                          0.0006154014789262348,\n",
              "                                                          0.0006153331256530192,\n",
              "                                                          0.0003920021771415983,\n",
              "                                                          0.01619845322936229,\n",
              "                                                          0.004779156784872302,\n",
              "                                                          0.007821074275112298,...\n",
              "                                                          0.005021425736625637,\n",
              "                                                          0.0005703073595961105,\n",
              "                                                          0.001151888789941251,\n",
              "                                                          0.001621231156394198,\n",
              "                                                          0.0024505367684280487,\n",
              "                                                          0.011155092541719619,\n",
              "                                                          0.0007524347058135697,\n",
              "                                                          0.0032032448128444043,\n",
              "                                                          0.004591455636549438,\n",
              "                                                          0.0003715541189658278, ...],\n",
              "                                        'n_hidden': [0, 1, 2, 3],\n",
              "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
              "                                                      10, 11, 12, 13, 14, 15,\n",
              "                                                      16, 17, 18, 19, 20, 21,\n",
              "                                                      22, 23, 24, 25, 26, 27,\n",
              "                                                      28, 29, 30, ...]},\n",
              "                   verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distribs = {\n",
        "    \"n_hidden\": [0, 1, 2, 3],\n",
        "    \"n_neurons\": np.arange(1, 100)               .tolist(),\n",
        "    \"learning_rate\": reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
        "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
        "                  validation_data=(X_valid, y_valid),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f47faae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f47faae",
        "outputId": "b916ebd6-5786-40e4-cc31-8fdf75429e85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.005803602934201024, 'n_hidden': 3, 'n_neurons': 74}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "rnd_search_cv.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b023aaf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b023aaf7",
        "outputId": "634b4c42-f54a-4d96-d712-8a74b829851b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.31959917147954303"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "rnd_search_cv.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "347a3ffe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "347a3ffe",
        "outputId": "44593616-3473-44d1-9fc2-ba061c90677e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.wrappers.scikit_learn.KerasRegressor at 0x7fc51538f150>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "rnd_search_cv.best_estimator_"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Lab9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}